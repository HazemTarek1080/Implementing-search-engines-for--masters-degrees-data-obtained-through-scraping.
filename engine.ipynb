{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment #3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "crawler.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import os\n",
    "\n",
    "def url_i(i):\n",
    "    url = \"https://www.findamasters.com/masters-degrees/msc-degrees/?PG={}\".format(i)\n",
    "    return url\n",
    "\n",
    "def get_MasterURLS():\n",
    "    for i in range(1, 401):\n",
    "        links_list = set()\n",
    "        url = url_i(i)\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            # Parse the HTML content\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            # Find all the links in the HTML\n",
    "            links = soup.find_all('a', href=True)\n",
    "            # Print all the links\n",
    "            for link in links:\n",
    "                l = link['href']\n",
    "                splitted = l.split(\"/\")\n",
    "                if splitted[-1][0:2] == \"?i\" and len(splitted[-1].split(\"#\")) != 2:\n",
    "                    links_list.add(l)\n",
    "        if len(links_list) == 15:\n",
    "            with open(\"links.txt\", 'a') as f:\n",
    "                for l in links_list:\n",
    "                    f.write(l+ '\\n')\n",
    "        time.sleep(1)\n",
    "\n",
    "def main():\n",
    "\n",
    "    get_MasterURLS()\n",
    "\n",
    "    j = 0\n",
    "\n",
    "    with open('links.txt', 'r') as file:\n",
    "        # Read the content of the file\n",
    "        file_content = file.readlines()\n",
    "        \n",
    "    for page in range(1, 401):\n",
    "        folder_name = \"page_{}\".format(page)\n",
    "        if not os.path.exists(folder_name):\n",
    "                os.makedirs(folder_name)\n",
    "        for web in range(j, 15 + j):\n",
    "            website = \"https://www.findamasters.com\" + file_content[web].replace(\"\\n\", \"\")\n",
    "            response = requests.get(website)\n",
    "            time.sleep(2)\n",
    "            with open(folder_name + \"/\" + \"page{}_master{}.html\".format(page, web), 'a', encoding='utf-8') as file:\n",
    "                file.write(response.text)\n",
    "        j = page * 15\n",
    "        print(\"Page \" + str(page) + \" has been completed.\")\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "parser.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import csv\n",
    "\n",
    "def getAdministration(s):\n",
    "    try:\n",
    "        administration = s[-1]\n",
    "    except IndexError:\n",
    "        administration = \" \"\n",
    "    return administration\n",
    "\n",
    "def getNamefromRegExpr(atrr, script_tags):\n",
    "    pattern = re.compile(r'DataLayerManager\\.{}\\s*=\\s*\"([^\"]+)\"'.format(atrr))\n",
    "    val = \"\"\n",
    "    for script_tag in script_tags:\n",
    "        script_content = script_tag.get_text()\n",
    "        match = pattern.search(script_content)\n",
    "        if match:\n",
    "            val = match.group(1)\n",
    "    return val\n",
    "\n",
    "def getDescription(soup):\n",
    "    description_section = soup.find('div', class_='course-sections__description')\n",
    "    if description_section:\n",
    "        description_title = description_section.find('h2', class_='course-sections__title').text\n",
    "        description_content = description_section.find('div', class_='course-sections__content').find('div', id='Snippet').text\n",
    "        return description_content.replace(\"\\n\", \"\")\n",
    "    else:\n",
    "        return \"\"\n",
    "    \n",
    "def getFees(soup):\n",
    "    fees_section = soup.find('div', class_='course-sections__fees')\n",
    "    if fees_section:\n",
    "        fees_title = fees_section.find('h2', class_='course-sections__title').text\n",
    "        fees_content = fees_section.find('div', class_='course-sections__content').text\n",
    "        return fees_content.replace(\"\\n\", \"\")\n",
    "    else:\n",
    "        return \"\"\n",
    "    \n",
    "\n",
    "\n",
    "def main():\n",
    "    folder_names = ['page_' + str(i) for i in range(1, 401)]\n",
    "\n",
    "    master = 0\n",
    "    masters = []\n",
    "    for folder in folder_names:\n",
    "        for i in range(15):\n",
    "            if master < 135:\n",
    "                num_folder = folder[-1]\n",
    "            elif master < 1485:\n",
    "                num_folder = folder[-2] + folder[-1]\n",
    "            else:\n",
    "                num_folder = folder[-3] + folder[-2] + folder[-1]\n",
    "            html_file = \"page\" + num_folder + \"_master\" + str(master)\n",
    "            with open(folder+\"/\"+html_file + \".html\", 'r', encoding='utf-8') as file:\n",
    "                html_content = file.read()\n",
    "            \n",
    "            soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "            script_tags = soup.find_all('script')\n",
    "            courseName = soup.title.text.strip().split(' at ')[0]\n",
    "            universityName = getNamefromRegExpr(\"dynamicInstitutionName\", script_tags)\n",
    "            facultyName = getNamefromRegExpr(\"dynamicDepartmentName\", script_tags)\n",
    "            isItFullTime = getNamefromRegExpr(\"dynamicStudyTypes\", script_tags).split(\",\")[0:-1]\n",
    "            description = getDescription(soup)\n",
    "            startDate = getNamefromRegExpr(\"dynamicStudyTerms\", script_tags)\n",
    "            fees = getFees(soup)\n",
    "            modality = getNamefromRegExpr(\"dynamicProgrammeTypes\", script_tags)\n",
    "            duration_elem = soup.find('span', class_='key-info__duration')\n",
    "            if duration_elem:\n",
    "                duration = duration_elem.text.strip()\n",
    "            else:\n",
    "                duration = \"\"\n",
    "            city_elem = soup.find('a', class_='course-data__city')\n",
    "            if city_elem:\n",
    "                city = city_elem.text.strip()\n",
    "            else:\n",
    "                city = \"\"\n",
    "            country = getNamefromRegExpr(\"dynamicLocationCountryName\", script_tags)\n",
    "            administration = getAdministration(getNamefromRegExpr(\"dynamicStudyTypes\", script_tags).split(\",\"))\n",
    "            url_e = soup.find('link', rel='canonical')\n",
    "            if url_e:\n",
    "                url = url_e.get('href', 'URL not available')\n",
    "            else:\n",
    "                url = \"\"\n",
    "            \n",
    "            with open(\"courses_tsv/course_{}.tsv\".format(master), 'a', encoding='utf-8-sig') as w:\n",
    "                writer = csv.writer(w, delimiter = '\\t')\n",
    "                writer.writerow([courseName, universityName, facultyName, isItFullTime, description, startDate, fees, modality, duration, city, country, administration, url])\n",
    "            master = master + 1\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Search engine "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hazem\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hazem\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import string\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import requests\n",
    "import numpy as np\n",
    "import time\n",
    "import folium\n",
    "from folium import IFrame\n",
    "from geopy.distance import geodesic\n",
    "from geopy.geocoders import Nominatim\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from IPython.display import display\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Script to create a DataFrame for the courses using the TSV files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Path to the folder containing TSV files\n",
    "folder_path = 'courses_tsv'\n",
    "\n",
    "dfs = []\n",
    "\n",
    "# Iterate over each file in the folder\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith('.tsv'):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        \n",
    "        # Read TSV file into a DataFrame\n",
    "        df = pd.read_csv(file_path, sep='\\t', header=None, names=[\n",
    "            'courseName', 'universityName', 'facultyName', 'isItFullTime',\n",
    "            'description', 'startDate', 'fees', 'modality', 'duration',\n",
    "            'city', 'country', 'administration', 'url'\n",
    "        ])\n",
    "        \n",
    "        # Append the DataFrame to the list\n",
    "        dfs.append(df)\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "final_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Write the DataFrame to a CSV file\n",
    "final_df.to_csv('masters_csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>courseName</th>\n",
       "      <th>universityName</th>\n",
       "      <th>facultyName</th>\n",
       "      <th>isItFullTime</th>\n",
       "      <th>description</th>\n",
       "      <th>startDate</th>\n",
       "      <th>fees</th>\n",
       "      <th>modality</th>\n",
       "      <th>duration</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>administration</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Air Quality Solutions - MSc</td>\n",
       "      <td>University of Leeds</td>\n",
       "      <td>Institute for Transport Studies</td>\n",
       "      <td>['Full Time', 'Part Time']</td>\n",
       "      <td>Up to 7 million people are estimated to die ev...</td>\n",
       "      <td>September</td>\n",
       "      <td>UK: £12,500 (Total) International: £28,750 (To...</td>\n",
       "      <td>MSc</td>\n",
       "      <td>1 year full time, 2 or 3 years part-time</td>\n",
       "      <td>Leeds</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>On Campus</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Agricultural, Environmental and Resource Econo...</td>\n",
       "      <td>University of Helsinki</td>\n",
       "      <td>International Masters Degree Programmes</td>\n",
       "      <td>['Full Time']</td>\n",
       "      <td>Goal of the pro­grammeAre you looking forward ...</td>\n",
       "      <td>September</td>\n",
       "      <td>Tuition fee per year (non-EU/EEA students): 15...</td>\n",
       "      <td>MSc</td>\n",
       "      <td>2 years</td>\n",
       "      <td>Helsinki</td>\n",
       "      <td>Finland</td>\n",
       "      <td>On Campus</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Accounting, Accountability &amp; Financial Managem...</td>\n",
       "      <td>King’s College London</td>\n",
       "      <td>King’s Business School</td>\n",
       "      <td>['Full Time']</td>\n",
       "      <td>Our Accounting, Accountability &amp; Financial Man...</td>\n",
       "      <td>September</td>\n",
       "      <td>Please see the university website for further ...</td>\n",
       "      <td>MSc</td>\n",
       "      <td>1 year FT</td>\n",
       "      <td>London</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>On Campus</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Energy and Environmental Sciences MSc</td>\n",
       "      <td>University of Groningen</td>\n",
       "      <td>Science and Engineering</td>\n",
       "      <td>['Full Time']</td>\n",
       "      <td>What are the causes of the various large scale...</td>\n",
       "      <td>September</td>\n",
       "      <td>Please see the university website for further ...</td>\n",
       "      <td>MSc</td>\n",
       "      <td>2 years full time</td>\n",
       "      <td>Groningen</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>On Campus</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Air Pollution Management and Control - MSc/PGDip</td>\n",
       "      <td>University of Birmingham</td>\n",
       "      <td>School of Geography, Earth and Environmental S...</td>\n",
       "      <td>['Full Time', 'Part Time']</td>\n",
       "      <td>Our Air Pollution Management and Control MSc i...</td>\n",
       "      <td>September</td>\n",
       "      <td>Please see the university website for further ...</td>\n",
       "      <td>PGDip,MSc</td>\n",
       "      <td>1 year full time, 2 years part time</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>On Campus</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          courseName  \\\n",
       "0                        Air Quality Solutions - MSc   \n",
       "1  Agricultural, Environmental and Resource Econo...   \n",
       "2  Accounting, Accountability & Financial Managem...   \n",
       "3              Energy and Environmental Sciences MSc   \n",
       "4   Air Pollution Management and Control - MSc/PGDip   \n",
       "\n",
       "             universityName  \\\n",
       "0       University of Leeds   \n",
       "1    University of Helsinki   \n",
       "2     King’s College London   \n",
       "3   University of Groningen   \n",
       "4  University of Birmingham   \n",
       "\n",
       "                                         facultyName  \\\n",
       "0                    Institute for Transport Studies   \n",
       "1            International Masters Degree Programmes   \n",
       "2                             King’s Business School   \n",
       "3                            Science and Engineering   \n",
       "4  School of Geography, Earth and Environmental S...   \n",
       "\n",
       "                 isItFullTime  \\\n",
       "0  ['Full Time', 'Part Time']   \n",
       "1               ['Full Time']   \n",
       "2               ['Full Time']   \n",
       "3               ['Full Time']   \n",
       "4  ['Full Time', 'Part Time']   \n",
       "\n",
       "                                         description  startDate  \\\n",
       "0  Up to 7 million people are estimated to die ev...  September   \n",
       "1  Goal of the pro­grammeAre you looking forward ...  September   \n",
       "2  Our Accounting, Accountability & Financial Man...  September   \n",
       "3  What are the causes of the various large scale...  September   \n",
       "4  Our Air Pollution Management and Control MSc i...  September   \n",
       "\n",
       "                                                fees   modality  \\\n",
       "0  UK: £12,500 (Total) International: £28,750 (To...        MSc   \n",
       "1  Tuition fee per year (non-EU/EEA students): 15...        MSc   \n",
       "2  Please see the university website for further ...        MSc   \n",
       "3  Please see the university website for further ...        MSc   \n",
       "4  Please see the university website for further ...  PGDip,MSc   \n",
       "\n",
       "                                   duration        city         country  \\\n",
       "0  1 year full time, 2 or 3 years part-time       Leeds  United Kingdom   \n",
       "1                                   2 years    Helsinki         Finland   \n",
       "2                                 1 year FT      London  United Kingdom   \n",
       "3                         2 years full time   Groningen     Netherlands   \n",
       "4       1 year full time, 2 years part time  Birmingham  United Kingdom   \n",
       "\n",
       "  administration                                                url  \n",
       "0      On Campus  https://www.findamasters.com/masters-degrees/c...  \n",
       "1      On Campus  https://www.findamasters.com/masters-degrees/c...  \n",
       "2      On Campus  https://www.findamasters.com/masters-degrees/c...  \n",
       "3      On Campus  https://www.findamasters.com/masters-degrees/c...  \n",
       "4      On Campus  https://www.findamasters.com/masters-degrees/c...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('masters_csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Search engine "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "\n",
    "    # Handling NaN/float values\n",
    "    if not isinstance(text, str):\n",
    "        return ''\n",
    "\n",
    "    # Converting the text to lower case\n",
    "    text = text.lower()\n",
    "\n",
    "    # Removing punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "    # Breaking the text into words(tokens)\n",
    "    words = nltk.word_tokenize(text)\n",
    "\n",
    "    # Removing stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "\n",
    "    # Stemming\n",
    "    stemmer = PorterStemmer()\n",
    "    words = [stemmer.stem(word) for word in words]\n",
    "\n",
    "    # Joining the list of words to form the processed text\n",
    "    processed_text = ' '.join(words)\n",
    "\n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing the fees column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Getting the currencies' USD exchange rates using fastforext API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AED: 3.67288\n",
      "AFN: 69.59229\n",
      "ALL: 93.79502\n",
      "AMD: 401.7486\n",
      "ANG: 1.78657\n",
      "AOA: 826.94932\n",
      "ARS: 357.66399\n",
      "AUD: 1.51772\n",
      "AWG: 1.79938\n",
      "AZN: 1.69103\n"
     ]
    }
   ],
   "source": [
    "url = 'https://api.fastforex.io/fetch-all'\n",
    "headers = {\n",
    "    'accept': 'application/json',\n",
    "}\n",
    "\n",
    "# Include the API key as a query parameter\n",
    "params = {\n",
    "    'api_key': '56359a1bde-e4fd75ffb0-s4bxgk',\n",
    "}\n",
    "\n",
    "# Make the GET request\n",
    "response = requests.get(url, headers=headers, params=params)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    exchange_rates = response.json()\n",
    "    \n",
    "\n",
    "else:\n",
    "    print('An error has occurred.')\n",
    "\n",
    "exchange_rates = exchange_rates['results']\n",
    "\n",
    "first_10_items = list(exchange_rates.items())[:10]\n",
    "\n",
    "for key, value in first_10_items:\n",
    "    print(f'{key}: {value}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Function that retrieves the tuition fees and its currency and converts it to USD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of currency symbols and their corresponding currency codes\n",
    "currency_symbols = {\n",
    "    'USD': '$',\n",
    "    'EUR': '€',\n",
    "    'GBP': '£',\n",
    "    'JPY': '¥',\n",
    "    'AUD': 'A$',\n",
    "    'CAD': 'C$',\n",
    "    'CHF': 'CHF',\n",
    "    'CNY': '¥',\n",
    "    'SEK': 'kr',\n",
    "    'NZD': 'NZ$',\n",
    "    'INR': '₹',\n",
    "    'SGD': 'S$',\n",
    "    'HKD': 'HK$',\n",
    "    'NOK': 'kr',\n",
    "    'KRW': '₩',\n",
    "    'TRY': '₺',\n",
    "    'ZAR': 'R',\n",
    "    'BRL': 'R$',\n",
    "    'RUB': '₽',\n",
    "    'MXN': 'Mex$',\n",
    "    'ARS': '$',\n",
    "    'IDR': 'Rp',\n",
    "    'MYR': 'RM',\n",
    "    'PHP': '₱',\n",
    "    'THB': '฿',\n",
    "    'CZK': 'Kč',\n",
    "    'HUF': 'Ft',\n",
    "    'PLN': 'zł',\n",
    "    'ISK': 'kr',\n",
    "    'DKK': 'kr',\n",
    "    'AED': 'د.إ',\n",
    "    'SAR': '﷼',\n",
    "    'QAR': '﷼',\n",
    "    'EGP': 'EGP',\n",
    "    'ILS': '₪',\n",
    "    'KWD': 'د.ك',\n",
    "    'BHD': 'ب.د',\n",
    "    'OMR': 'ر.ع.',\n",
    "    'JOD': 'د.ا',\n",
    "    'LBP': 'ل.ل',\n",
    "    'JMD': 'J$',\n",
    "    'TTD': 'TT$',\n",
    "    'COP': 'COL$',\n",
    "    'CLP': 'CLP$',\n",
    "    'PEN': 'S/',\n",
    "    'UYU': '$U',\n",
    "    'CRC': '₡',\n",
    "}\n",
    "\n",
    "\n",
    "def extract_and_convert_fees(row, exchange_rates):\n",
    "\n",
    "    fees_usd = 0  \n",
    "    \n",
    "# Regex to find the tuition fees\n",
    "\n",
    "    for currency, symbol in currency_symbols.items():\n",
    "\n",
    "        regex = rf'{symbol}(\\d+(?:,\\d{{3}})*(\\.\\d+)?)'\n",
    "        matches = re.findall(regex, row)\n",
    "\n",
    "        for match in matches:\n",
    "\n",
    "            # Remove commas and convert to float\n",
    "            num = float(match[0].replace(',', ''))\n",
    "            # Multiply by the conversion rate to get the amount in USD\n",
    "            if currency in exchange_rates:\n",
    "                num *= exchange_rates[currency]\n",
    "                fees_usd = max(fees_usd, num)\n",
    "\n",
    "    return fees_usd\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying text-preprocessing to the column 'description' and adding the column 'fees_USD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_updated = df.copy()\n",
    "\n",
    "# Preprocess the text in the description, courseName, universityName and city columns \n",
    "df_updated['description_lemmatized'] = df_updated['description'].apply(preprocess_text)\n",
    "df_updated['courseName_lemmatized'] = df_updated['courseName'].apply(preprocess_text)\n",
    "df_updated['universityName_lemmatized'] = df_updated['universityName'].apply(preprocess_text)\n",
    "df_updated['city_lemmatized'] = df_updated['city'].apply(preprocess_text)\n",
    "\n",
    "# Create the fees_USD column with the equivalent tuition in USD\n",
    "df_updated['fees_USD'] = df_updated['fees'].apply(lambda row: extract_and_convert_fees(str(row), exchange_rates) if not pd.isnull(row) else np.nan)\n",
    "df_updated['fees_USD'] = df_updated['fees_USD'].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>courseName</th>\n",
       "      <th>universityName</th>\n",
       "      <th>facultyName</th>\n",
       "      <th>isItFullTime</th>\n",
       "      <th>description</th>\n",
       "      <th>startDate</th>\n",
       "      <th>fees</th>\n",
       "      <th>modality</th>\n",
       "      <th>duration</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>administration</th>\n",
       "      <th>url</th>\n",
       "      <th>description_lemmatized</th>\n",
       "      <th>courseName_lemmatized</th>\n",
       "      <th>universityName_lemmatized</th>\n",
       "      <th>city_lemmatized</th>\n",
       "      <th>fees_USD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Air Quality Solutions - MSc</td>\n",
       "      <td>University of Leeds</td>\n",
       "      <td>Institute for Transport Studies</td>\n",
       "      <td>['Full Time', 'Part Time']</td>\n",
       "      <td>Up to 7 million people are estimated to die ev...</td>\n",
       "      <td>September</td>\n",
       "      <td>UK: £12,500 (Total) International: £28,750 (To...</td>\n",
       "      <td>MSc</td>\n",
       "      <td>1 year full time, 2 or 3 years part-time</td>\n",
       "      <td>Leeds</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>On Campus</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "      <td>7 million peopl estim die everi year due harm ...</td>\n",
       "      <td>air qualiti solut msc</td>\n",
       "      <td>univers leed</td>\n",
       "      <td>leed</td>\n",
       "      <td>22809.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Analytical Chemistry (MSc)</td>\n",
       "      <td>Sheffield Hallam University</td>\n",
       "      <td>Postgraduate Courses</td>\n",
       "      <td>['Full Time', 'Part Time']</td>\n",
       "      <td>Apply for the part-time course here.Work in cu...</td>\n",
       "      <td>September</td>\n",
       "      <td>Our tuition fee for UK students starting full-...</td>\n",
       "      <td>MSc,PGDip,PGCert</td>\n",
       "      <td>1 year full-time, 2 years part-time</td>\n",
       "      <td>Sheffield</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>On Campus</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "      <td>appli parttim cours herework cuttingedg facil ...</td>\n",
       "      <td>analyt chemistri msc</td>\n",
       "      <td>sheffield hallam univers</td>\n",
       "      <td>sheffield</td>\n",
       "      <td>8179.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Economics of Sustainability</td>\n",
       "      <td>Erasmus School of Economics</td>\n",
       "      <td>Masters Programmes</td>\n",
       "      <td>['Full Time']</td>\n",
       "      <td>Master in Economics of Sustainability: Focus o...</td>\n",
       "      <td>September</td>\n",
       "      <td>Tuition fees (2023-2024)  €2.314 (Statutory fe...</td>\n",
       "      <td>MSc</td>\n",
       "      <td>1 year</td>\n",
       "      <td>Rotterdam</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>On Campus</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "      <td>master econom sustain focu sustain develop eco...</td>\n",
       "      <td>econom sustain</td>\n",
       "      <td>erasmu school econom</td>\n",
       "      <td>rotterdam</td>\n",
       "      <td>14.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Allergy &amp; Clinical Immunology (Online) PGCert</td>\n",
       "      <td>University College Cork</td>\n",
       "      <td>College of Medicine and Health</td>\n",
       "      <td>['Part Time']</td>\n",
       "      <td>This new Postgraduate Certificate in Allergy a...</td>\n",
       "      <td>September</td>\n",
       "      <td>The EU fee for this course is €3,130.  The Non...</td>\n",
       "      <td>PGCert,PGDip,MSc</td>\n",
       "      <td>1 year part time</td>\n",
       "      <td>Cork</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>Online</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "      <td>new postgradu certif allergi clinic immunolog ...</td>\n",
       "      <td>allergi clinic immunolog onlin pgcert</td>\n",
       "      <td>univers colleg cork</td>\n",
       "      <td>cork</td>\n",
       "      <td>6352.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Anaesthesia and Perioperative Science MSc</td>\n",
       "      <td>University College London</td>\n",
       "      <td>Division of Surgery and Interventional Science</td>\n",
       "      <td>['Part Time']</td>\n",
       "      <td>Register your interest in graduate study at UC...</td>\n",
       "      <td>March, September</td>\n",
       "      <td>Part time - £7,050</td>\n",
       "      <td>MSc</td>\n",
       "      <td>2 years part time</td>\n",
       "      <td>London</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>On Campus</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "      <td>regist interest graduat studi uclth msc anaest...</td>\n",
       "      <td>anaesthesia periop scienc msc</td>\n",
       "      <td>univers colleg london</td>\n",
       "      <td>london</td>\n",
       "      <td>5593.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Analytics and Operations Research in Logistics...</td>\n",
       "      <td>Erasmus School of Economics</td>\n",
       "      <td>Masters Programmes</td>\n",
       "      <td>['Full Time']</td>\n",
       "      <td>Are you curious how logistics companies solve ...</td>\n",
       "      <td>September</td>\n",
       "      <td>Tuition fees (2023-2024)  €2.314 (Statutory fe...</td>\n",
       "      <td>MSc</td>\n",
       "      <td>1 year</td>\n",
       "      <td>Rotterdam</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>On Campus</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "      <td>curiou logist compani solv puzzl rout vehicl s...</td>\n",
       "      <td>analyt oper research logist msc</td>\n",
       "      <td>erasmu school econom</td>\n",
       "      <td>rotterdam</td>\n",
       "      <td>14.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Energy Policy and Finance (MSc)</td>\n",
       "      <td>University of St Andrews</td>\n",
       "      <td>Interdisciplinary Studies</td>\n",
       "      <td>['Full Time', 'Part Time']</td>\n",
       "      <td>The MSc in Energy Ethics explores how we balan...</td>\n",
       "      <td>September</td>\n",
       "      <td>Home £13,470  Overseas £27,230</td>\n",
       "      <td>MSc</td>\n",
       "      <td>1 year full time, 2 year part time</td>\n",
       "      <td>St Andrews</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>On Campus</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "      <td>msc energi ethic explor balanc energi demand c...</td>\n",
       "      <td>energi polici financ msc</td>\n",
       "      <td>univers st andrew</td>\n",
       "      <td>st andrew</td>\n",
       "      <td>21603.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Anthropology, Environment and Development MSc</td>\n",
       "      <td>University College London</td>\n",
       "      <td>Department of Anthropology</td>\n",
       "      <td>['Full Time', 'Part Time']</td>\n",
       "      <td>Register your interest in graduate study at UC...</td>\n",
       "      <td>September</td>\n",
       "      <td>Full time - £14,100 Part time - £7,050</td>\n",
       "      <td>MSc</td>\n",
       "      <td>1 year full time, 2 years part time</td>\n",
       "      <td>London</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>On Campus</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "      <td>regist interest graduat studi uclth msc anthro...</td>\n",
       "      <td>anthropolog environ develop msc</td>\n",
       "      <td>univers colleg london</td>\n",
       "      <td>london</td>\n",
       "      <td>11186.52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           courseName  \\\n",
       "0                         Air Quality Solutions - MSc   \n",
       "13                         Analytical Chemistry (MSc)   \n",
       "14                        Economics of Sustainability   \n",
       "18      Allergy & Clinical Immunology (Online) PGCert   \n",
       "19          Anaesthesia and Perioperative Science MSc   \n",
       "41  Analytics and Operations Research in Logistics...   \n",
       "47                    Energy Policy and Finance (MSc)   \n",
       "53      Anthropology, Environment and Development MSc   \n",
       "\n",
       "                 universityName  \\\n",
       "0           University of Leeds   \n",
       "13  Sheffield Hallam University   \n",
       "14  Erasmus School of Economics   \n",
       "18      University College Cork   \n",
       "19    University College London   \n",
       "41  Erasmus School of Economics   \n",
       "47     University of St Andrews   \n",
       "53    University College London   \n",
       "\n",
       "                                       facultyName  \\\n",
       "0                  Institute for Transport Studies   \n",
       "13                            Postgraduate Courses   \n",
       "14                              Masters Programmes   \n",
       "18                  College of Medicine and Health   \n",
       "19  Division of Surgery and Interventional Science   \n",
       "41                              Masters Programmes   \n",
       "47                       Interdisciplinary Studies   \n",
       "53                      Department of Anthropology   \n",
       "\n",
       "                  isItFullTime  \\\n",
       "0   ['Full Time', 'Part Time']   \n",
       "13  ['Full Time', 'Part Time']   \n",
       "14               ['Full Time']   \n",
       "18               ['Part Time']   \n",
       "19               ['Part Time']   \n",
       "41               ['Full Time']   \n",
       "47  ['Full Time', 'Part Time']   \n",
       "53  ['Full Time', 'Part Time']   \n",
       "\n",
       "                                          description         startDate  \\\n",
       "0   Up to 7 million people are estimated to die ev...         September   \n",
       "13  Apply for the part-time course here.Work in cu...         September   \n",
       "14  Master in Economics of Sustainability: Focus o...         September   \n",
       "18  This new Postgraduate Certificate in Allergy a...         September   \n",
       "19  Register your interest in graduate study at UC...  March, September   \n",
       "41  Are you curious how logistics companies solve ...         September   \n",
       "47  The MSc in Energy Ethics explores how we balan...         September   \n",
       "53  Register your interest in graduate study at UC...         September   \n",
       "\n",
       "                                                 fees          modality  \\\n",
       "0   UK: £12,500 (Total) International: £28,750 (To...               MSc   \n",
       "13  Our tuition fee for UK students starting full-...  MSc,PGDip,PGCert   \n",
       "14  Tuition fees (2023-2024)  €2.314 (Statutory fe...               MSc   \n",
       "18  The EU fee for this course is €3,130.  The Non...  PGCert,PGDip,MSc   \n",
       "19                                 Part time - £7,050               MSc   \n",
       "41  Tuition fees (2023-2024)  €2.314 (Statutory fe...               MSc   \n",
       "47                     Home £13,470  Overseas £27,230               MSc   \n",
       "53             Full time - £14,100 Part time - £7,050               MSc   \n",
       "\n",
       "                                    duration        city         country  \\\n",
       "0   1 year full time, 2 or 3 years part-time       Leeds  United Kingdom   \n",
       "13       1 year full-time, 2 years part-time   Sheffield  United Kingdom   \n",
       "14                                    1 year   Rotterdam     Netherlands   \n",
       "18                          1 year part time        Cork         Ireland   \n",
       "19                         2 years part time      London  United Kingdom   \n",
       "41                                    1 year   Rotterdam     Netherlands   \n",
       "47        1 year full time, 2 year part time  St Andrews  United Kingdom   \n",
       "53       1 year full time, 2 years part time      London  United Kingdom   \n",
       "\n",
       "   administration                                                url  \\\n",
       "0       On Campus  https://www.findamasters.com/masters-degrees/c...   \n",
       "13      On Campus  https://www.findamasters.com/masters-degrees/c...   \n",
       "14      On Campus  https://www.findamasters.com/masters-degrees/c...   \n",
       "18         Online  https://www.findamasters.com/masters-degrees/c...   \n",
       "19      On Campus  https://www.findamasters.com/masters-degrees/c...   \n",
       "41      On Campus  https://www.findamasters.com/masters-degrees/c...   \n",
       "47      On Campus  https://www.findamasters.com/masters-degrees/c...   \n",
       "53      On Campus  https://www.findamasters.com/masters-degrees/c...   \n",
       "\n",
       "                               description_lemmatized  \\\n",
       "0   7 million peopl estim die everi year due harm ...   \n",
       "13  appli parttim cours herework cuttingedg facil ...   \n",
       "14  master econom sustain focu sustain develop eco...   \n",
       "18  new postgradu certif allergi clinic immunolog ...   \n",
       "19  regist interest graduat studi uclth msc anaest...   \n",
       "41  curiou logist compani solv puzzl rout vehicl s...   \n",
       "47  msc energi ethic explor balanc energi demand c...   \n",
       "53  regist interest graduat studi uclth msc anthro...   \n",
       "\n",
       "                    courseName_lemmatized universityName_lemmatized  \\\n",
       "0                   air qualiti solut msc              univers leed   \n",
       "13                   analyt chemistri msc  sheffield hallam univers   \n",
       "14                         econom sustain      erasmu school econom   \n",
       "18  allergi clinic immunolog onlin pgcert       univers colleg cork   \n",
       "19          anaesthesia periop scienc msc     univers colleg london   \n",
       "41        analyt oper research logist msc      erasmu school econom   \n",
       "47               energi polici financ msc         univers st andrew   \n",
       "53        anthropolog environ develop msc     univers colleg london   \n",
       "\n",
       "   city_lemmatized  fees_USD  \n",
       "0             leed  22809.39  \n",
       "13       sheffield   8179.64  \n",
       "14       rotterdam     14.72  \n",
       "18            cork   6352.37  \n",
       "19          london   5593.26  \n",
       "41       rotterdam     14.72  \n",
       "47       st andrew  21603.47  \n",
       "53          london  11186.52  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Masters degrees with tuition fees mentioned in the scraped data\n",
    "dummy = df_updated[df_updated['fees_USD'] != 0]\n",
    "dummy.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conjunctive Querying"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the words vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a vocabulary\n",
    "vocabulary = set()\n",
    "\n",
    "# Extract words from the 'description' column\n",
    "for description in df_updated['description_lemmatized']:\n",
    "     \n",
    "     # Handling NaN/float values\n",
    "     if isinstance(description, str):  \n",
    "        words = description.split()\n",
    "        vocabulary.update(words)\n",
    "\n",
    "# Convert the vocabulary to a dictionary with words as keys and their index as values\n",
    "vocabulary_dict = {idx: word for idx, word in enumerate(vocabulary)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the inverted index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>documents_IDs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hurdl</td>\n",
       "      <td>[1533]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tradetheoret</td>\n",
       "      <td>[95]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>transductionom</td>\n",
       "      <td>[3966]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>techniquesstudi</td>\n",
       "      <td>[476]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>master®</td>\n",
       "      <td>[4074]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              word documents_IDs\n",
       "0            hurdl        [1533]\n",
       "1     tradetheoret          [95]\n",
       "2   transductionom        [3966]\n",
       "3  techniquesstudi         [476]\n",
       "4          master®        [4074]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dictionary to store word occurrences with row indices\n",
    "inverted_index = {word: [] for word in vocabulary}\n",
    "\n",
    "# Iterate over rows to find occurrences\n",
    "i = 0\n",
    "for idx, description in enumerate(df_updated['description_lemmatized']):\n",
    "\n",
    "    # Handling NaN/float values\n",
    "    if isinstance(description, str):  \n",
    "        words = description.split()\n",
    "        for word in words:\n",
    "            if word in vocabulary:\n",
    "                inverted_index[word].append(idx)\n",
    "    \n",
    "\n",
    "# Create a DataFrame from the dictionary\n",
    "inverted_index = pd.DataFrame(list(inverted_index.items()), columns=['word', 'documents_IDs'])\n",
    "inverted_index['documents_IDs'] = inverted_index['documents_IDs'].apply(lambda x: list(set(x)))\n",
    "inverted_index.to_csv('inverted_index.csv', index=False)\n",
    "inverted_index.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to process the search query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_query(query, inverted_index, df):\n",
    "    \n",
    "    # Apply text preprocessing to the query\n",
    "    processed_query = preprocess_text(query)\n",
    "\n",
    "    query_words = processed_query.split()\n",
    "\n",
    "    # Find document_IDs for each word in the query using the inverted index\n",
    "    result_document_ids = []\n",
    "    \n",
    "    for word in query_words:\n",
    "\n",
    "        if word in inverted_index['word'].values:\n",
    "\n",
    "            # Get the document_IDs for the current word\n",
    "            word_document_ids = inverted_index.loc[inverted_index['word'] == word, 'documents_IDs'].values[0]\n",
    "\n",
    "            # Add the document_IDs to the result list\n",
    "            result_document_ids.extend(word_document_ids)\n",
    "\n",
    "    # Remove duplicate document_IDs\n",
    "    result_document_ids = list(set(result_document_ids))\n",
    "    result_document_ids.sort()\n",
    "    \n",
    "    # Return the rows corresponding to the document_IDs\n",
    "    return df_updated.loc[result_document_ids, ['courseName', 'universityName', 'description', 'city', 'url']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of results: 2491\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>courseName</th>\n",
       "      <th>universityName</th>\n",
       "      <th>description</th>\n",
       "      <th>city</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Accounting, Accountability &amp; Financial Managem...</td>\n",
       "      <td>King’s College London</td>\n",
       "      <td>Our Accounting, Accountability &amp; Financial Man...</td>\n",
       "      <td>London</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Airline and Airport Corporate Management</td>\n",
       "      <td>London Metropolitan University</td>\n",
       "      <td>Why study this course?This innovative master's...</td>\n",
       "      <td>London</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Analogue and Digital Integrated Circuit Design...</td>\n",
       "      <td>Imperial College London</td>\n",
       "      <td>Our MSc in Analogue and Digital Integrated Cir...</td>\n",
       "      <td>London</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Analytical Chemistry (MSc)</td>\n",
       "      <td>Sheffield Hallam University</td>\n",
       "      <td>Apply for the part-time course here.Work in cu...</td>\n",
       "      <td>Sheffield</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Allergy - MSc/PGDip/PGCert</td>\n",
       "      <td>Imperial College London</td>\n",
       "      <td>Allergy is an increasing global health problem...</td>\n",
       "      <td>London</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           courseName  \\\n",
       "2   Accounting, Accountability & Financial Managem...   \n",
       "7            Airline and Airport Corporate Management   \n",
       "11  Analogue and Digital Integrated Circuit Design...   \n",
       "13                         Analytical Chemistry (MSc)   \n",
       "22                         Allergy - MSc/PGDip/PGCert   \n",
       "\n",
       "                    universityName  \\\n",
       "2            King’s College London   \n",
       "7   London Metropolitan University   \n",
       "11         Imperial College London   \n",
       "13     Sheffield Hallam University   \n",
       "22         Imperial College London   \n",
       "\n",
       "                                          description       city  \\\n",
       "2   Our Accounting, Accountability & Financial Man...     London   \n",
       "7   Why study this course?This innovative master's...     London   \n",
       "11  Our MSc in Analogue and Digital Integrated Cir...     London   \n",
       "13  Apply for the part-time course here.Work in cu...  Sheffield   \n",
       "22  Allergy is an increasing global health problem...     London   \n",
       "\n",
       "                                                  url  \n",
       "2   https://www.findamasters.com/masters-degrees/c...  \n",
       "7   https://www.findamasters.com/masters-degrees/c...  \n",
       "11  https://www.findamasters.com/masters-degrees/c...  \n",
       "13  https://www.findamasters.com/masters-degrees/c...  \n",
       "22  https://www.findamasters.com/masters-degrees/c...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_query = 'advanced knowledge'\n",
    "result = execute_query(sample_query, inverted_index, df_updated)\n",
    "print(f'Number of results: {len(result)}')\n",
    "result.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conjunctive querying and Ranking Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hurdl</th>\n",
       "      <th>tradetheoret</th>\n",
       "      <th>transductionom</th>\n",
       "      <th>techniquesstudi</th>\n",
       "      <th>master®</th>\n",
       "      <th>companygain</th>\n",
       "      <th>careerwhen</th>\n",
       "      <th>offenc</th>\n",
       "      <th>worldwidey</th>\n",
       "      <th>kaust</th>\n",
       "      <th>...</th>\n",
       "      <th>40thi</th>\n",
       "      <th>bestqual</th>\n",
       "      <th>coorgan</th>\n",
       "      <th>beat</th>\n",
       "      <th>entrench</th>\n",
       "      <th>ul</th>\n",
       "      <th>ghana</th>\n",
       "      <th>materialsthi</th>\n",
       "      <th>datasetsthi</th>\n",
       "      <th>harm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.298859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 14742 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   hurdl  tradetheoret  transductionom  techniquesstudi  master®  companygain  \\\n",
       "0    0.0           0.0             0.0              0.0      0.0          0.0   \n",
       "1    0.0           0.0             0.0              0.0      0.0          0.0   \n",
       "2    0.0           0.0             0.0              0.0      0.0          0.0   \n",
       "3    0.0           0.0             0.0              0.0      0.0          0.0   \n",
       "4    0.0           0.0             0.0              0.0      0.0          0.0   \n",
       "\n",
       "   careerwhen  offenc  worldwidey  kaust  ...  40thi  bestqual  coorgan  beat  \\\n",
       "0         0.0     0.0         0.0    0.0  ...    0.0       0.0      0.0   0.0   \n",
       "1         0.0     0.0         0.0    0.0  ...    0.0       0.0      0.0   0.0   \n",
       "2         0.0     0.0         0.0    0.0  ...    0.0       0.0      0.0   0.0   \n",
       "3         0.0     0.0         0.0    0.0  ...    0.0       0.0      0.0   0.0   \n",
       "4         0.0     0.0         0.0    0.0  ...    0.0       0.0      0.0   0.0   \n",
       "\n",
       "   entrench   ul  ghana  materialsthi  datasetsthi      harm  \n",
       "0       0.0  0.0    0.0           0.0          0.0  0.298859  \n",
       "1       0.0  0.0    0.0           0.0          0.0  0.000000  \n",
       "2       0.0  0.0    0.0           0.0          0.0  0.000000  \n",
       "3       0.0  0.0    0.0           0.0          0.0  0.000000  \n",
       "4       0.0  0.0    0.0           0.0          0.0  0.000000  \n",
       "\n",
       "[5 rows x 14742 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF Vectorization\n",
    "tfidf_vectorizer = TfidfVectorizer(vocabulary=inverted_index['word'].values)\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df_updated['description_lemmatized'])\n",
    "\n",
    "# Convert the TF-IDF matrix to a DataFrame for better visualization\n",
    "df_tfidf = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names_out(), index=df_updated.index)\n",
    "df_tfidf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>documents_IDs</th>\n",
       "      <th>documents_tfidf_pairs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hurdl</td>\n",
       "      <td>[1533]</td>\n",
       "      <td>[(1533, 0.2029373291033616)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tradetheoret</td>\n",
       "      <td>[95]</td>\n",
       "      <td>[(95, 0.16391621097937675)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>transductionom</td>\n",
       "      <td>[3966]</td>\n",
       "      <td>[(3966, 0.15916076607128118)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>techniquesstudi</td>\n",
       "      <td>[476]</td>\n",
       "      <td>[(476, 0.21124066478102543)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>master®</td>\n",
       "      <td>[4074]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              word documents_IDs          documents_tfidf_pairs\n",
       "0            hurdl        [1533]   [(1533, 0.2029373291033616)]\n",
       "1     tradetheoret          [95]    [(95, 0.16391621097937675)]\n",
       "2   transductionom        [3966]  [(3966, 0.15916076607128118)]\n",
       "3  techniquesstudi         [476]   [(476, 0.21124066478102543)]\n",
       "4          master®        [4074]                             []"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the new inverted index\n",
    "inverted_index_tfidf = inverted_index.copy()\n",
    "\n",
    "# create a new column to store the document-tfidf pairs to match the format required\n",
    "inverted_index_tfidf['documents_tfidf_pairs'] = inverted_index_tfidf.word.apply(lambda word: [(doc_id, df_tfidf.loc[doc_id, word]) for doc_id in df_tfidf.index if df_tfidf.loc[doc_id, word] > 0])\n",
    "inverted_index_tfidf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Function that executes the query by applying cosine similarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_query_modified(query, inverted_index_tfidf, df, df_tfidf, tfidf_vectorizer):\n",
    "\n",
    "    # Preprocess the query\n",
    "    query_words = preprocess_text(query).split()\n",
    "\n",
    "    # Find related documents\n",
    "    related_docs = set.intersection(*(\n",
    "        set(id for id, _ in inverted_index_tfidf.loc[inverted_index_tfidf['word'] == word, 'documents_tfidf_pairs'].iloc[0])\n",
    "        for word in query_words\n",
    "        if word in inverted_index_tfidf['word'].values\n",
    "    ))\n",
    "\n",
    "    # Return an empty DataFrame if no related documents were found\n",
    "    if not related_docs:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Calculate cosine similarity for each document\n",
    "    query_vectorized = tfidf_vectorizer.transform([' '.join(query_words)])\n",
    "    similarities = {id: cosine_similarity(query_vectorized, df_tfidf.loc[id].values.reshape(1, -1))[0][0] for id in related_docs}\n",
    "\n",
    "    # Sort documents by their similarity score\n",
    "    sorted_doc_ids = sorted(similarities, key=similarities.get, reverse=True)\n",
    "\n",
    "    output = df.loc[sorted_doc_ids, ['courseName', 'universityName', 'description', 'city', 'fees_USD', 'url']]\n",
    "    output['similarity'] = [similarities[id] for id in sorted_doc_ids]\n",
    "\n",
    "    return output.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Executing the function using the query \"advanced knowledge\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>courseName</th>\n",
       "      <th>universityName</th>\n",
       "      <th>description</th>\n",
       "      <th>city</th>\n",
       "      <th>fees_USD</th>\n",
       "      <th>url</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Advanced Computing MSc</td>\n",
       "      <td>King’s College London</td>\n",
       "      <td>Our Advanced Computing MSc provides knowledge ...</td>\n",
       "      <td>London</td>\n",
       "      <td>0.00</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "      <td>0.394639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Advancing Practice - MSc</td>\n",
       "      <td>University of Northampton</td>\n",
       "      <td>Our MSc Advancing Practice awards support the ...</td>\n",
       "      <td>Northampton</td>\n",
       "      <td>0.00</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "      <td>0.380455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Advanced Healthcare Practice - MSc</td>\n",
       "      <td>Cardiff University</td>\n",
       "      <td>Why study this courseOur MSc Advanced Healthca...</td>\n",
       "      <td>Cardiff</td>\n",
       "      <td>0.00</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "      <td>0.379754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Advanced Clinical Practice - MSc</td>\n",
       "      <td>Canterbury Christ Church University</td>\n",
       "      <td>Gain the knowledge and skills needed to become...</td>\n",
       "      <td>Canterbury</td>\n",
       "      <td>1289.08</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "      <td>0.359401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Advanced Mechanical Engineering - MSc (Eng)</td>\n",
       "      <td>University of Leeds</td>\n",
       "      <td>This course offers a broad range of advanced s...</td>\n",
       "      <td>Leeds</td>\n",
       "      <td>24820.77</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "      <td>0.337821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Advanced Biomedical Engineering - MSc</td>\n",
       "      <td>University of Bradford</td>\n",
       "      <td>Biomedical engineering is a fast evolving inte...</td>\n",
       "      <td>Bradford</td>\n",
       "      <td>0.00</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "      <td>0.316692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Advanced Clinical Practice - MSc</td>\n",
       "      <td>University of Northampton</td>\n",
       "      <td>Our MSc Advanced Clinical Practice course aims...</td>\n",
       "      <td>Northampton</td>\n",
       "      <td>0.00</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "      <td>0.311848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Advanced Professional Practice (MSc)</td>\n",
       "      <td>University of Gloucestershire</td>\n",
       "      <td>Our lecturers are research active experts who ...</td>\n",
       "      <td>Gloucester</td>\n",
       "      <td>0.00</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "      <td>0.311319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Advanced Computing - MSc</td>\n",
       "      <td>University of the West of Scotland</td>\n",
       "      <td>Our MSc Advanced Computing course is designed ...</td>\n",
       "      <td>Glasgow</td>\n",
       "      <td>0.00</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "      <td>0.305071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Advanced Clinical Practice (AHP) - MSc/PGDip/P...</td>\n",
       "      <td>Bangor University</td>\n",
       "      <td>The programme has been developed to enhance pr...</td>\n",
       "      <td>Bangor</td>\n",
       "      <td>0.00</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "      <td>0.299051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Advanced Clinical Practitioner - MSc</td>\n",
       "      <td>University of Sunderland</td>\n",
       "      <td>The MSc Advanced Clinical Practitioner is a hi...</td>\n",
       "      <td>Sunderland</td>\n",
       "      <td>0.00</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "      <td>0.296599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Advanced Computer Science - MSc/PgD/PgC</td>\n",
       "      <td>Cardiff Metropolitan University</td>\n",
       "      <td>This Master's degree in Advanced Computer Scie...</td>\n",
       "      <td>Cardiff</td>\n",
       "      <td>0.00</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "      <td>0.295198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Advanced Practice in Healthcare MSc</td>\n",
       "      <td>University of Liverpool</td>\n",
       "      <td>Explore specialist areas of practice in-depth ...</td>\n",
       "      <td>Liverpool</td>\n",
       "      <td>2775.92</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "      <td>0.294579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Management and Digital Business (with Advanced...</td>\n",
       "      <td>Liverpool John Moores University</td>\n",
       "      <td>This Advanced Practice course provides an in-d...</td>\n",
       "      <td>Liverpool</td>\n",
       "      <td>0.00</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "      <td>0.294348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Advanced Practice in Healthcare - MSc/PGDip/PG...</td>\n",
       "      <td>University of Birmingham</td>\n",
       "      <td>The MSc Advanced Practice in Healthcare is aim...</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>0.00</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "      <td>0.279512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           courseName  \\\n",
       "0                              Advanced Computing MSc   \n",
       "1                            Advancing Practice - MSc   \n",
       "2                  Advanced Healthcare Practice - MSc   \n",
       "3                    Advanced Clinical Practice - MSc   \n",
       "4         Advanced Mechanical Engineering - MSc (Eng)   \n",
       "5               Advanced Biomedical Engineering - MSc   \n",
       "6                    Advanced Clinical Practice - MSc   \n",
       "7                Advanced Professional Practice (MSc)   \n",
       "8                            Advanced Computing - MSc   \n",
       "9   Advanced Clinical Practice (AHP) - MSc/PGDip/P...   \n",
       "10               Advanced Clinical Practitioner - MSc   \n",
       "11            Advanced Computer Science - MSc/PgD/PgC   \n",
       "12                Advanced Practice in Healthcare MSc   \n",
       "13  Management and Digital Business (with Advanced...   \n",
       "14  Advanced Practice in Healthcare - MSc/PGDip/PG...   \n",
       "\n",
       "                         universityName  \\\n",
       "0                 King’s College London   \n",
       "1             University of Northampton   \n",
       "2                    Cardiff University   \n",
       "3   Canterbury Christ Church University   \n",
       "4                   University of Leeds   \n",
       "5                University of Bradford   \n",
       "6             University of Northampton   \n",
       "7         University of Gloucestershire   \n",
       "8    University of the West of Scotland   \n",
       "9                     Bangor University   \n",
       "10             University of Sunderland   \n",
       "11      Cardiff Metropolitan University   \n",
       "12              University of Liverpool   \n",
       "13     Liverpool John Moores University   \n",
       "14             University of Birmingham   \n",
       "\n",
       "                                          description         city  fees_USD  \\\n",
       "0   Our Advanced Computing MSc provides knowledge ...       London      0.00   \n",
       "1   Our MSc Advancing Practice awards support the ...  Northampton      0.00   \n",
       "2   Why study this courseOur MSc Advanced Healthca...      Cardiff      0.00   \n",
       "3   Gain the knowledge and skills needed to become...   Canterbury   1289.08   \n",
       "4   This course offers a broad range of advanced s...        Leeds  24820.77   \n",
       "5   Biomedical engineering is a fast evolving inte...     Bradford      0.00   \n",
       "6   Our MSc Advanced Clinical Practice course aims...  Northampton      0.00   \n",
       "7   Our lecturers are research active experts who ...   Gloucester      0.00   \n",
       "8   Our MSc Advanced Computing course is designed ...      Glasgow      0.00   \n",
       "9   The programme has been developed to enhance pr...       Bangor      0.00   \n",
       "10  The MSc Advanced Clinical Practitioner is a hi...   Sunderland      0.00   \n",
       "11  This Master's degree in Advanced Computer Scie...      Cardiff      0.00   \n",
       "12  Explore specialist areas of practice in-depth ...    Liverpool   2775.92   \n",
       "13  This Advanced Practice course provides an in-d...    Liverpool      0.00   \n",
       "14  The MSc Advanced Practice in Healthcare is aim...   Birmingham      0.00   \n",
       "\n",
       "                                                  url  similarity  \n",
       "0   https://www.findamasters.com/masters-degrees/c...    0.394639  \n",
       "1   https://www.findamasters.com/masters-degrees/c...    0.380455  \n",
       "2   https://www.findamasters.com/masters-degrees/c...    0.379754  \n",
       "3   https://www.findamasters.com/masters-degrees/c...    0.359401  \n",
       "4   https://www.findamasters.com/masters-degrees/c...    0.337821  \n",
       "5   https://www.findamasters.com/masters-degrees/c...    0.316692  \n",
       "6   https://www.findamasters.com/masters-degrees/c...    0.311848  \n",
       "7   https://www.findamasters.com/masters-degrees/c...    0.311319  \n",
       "8   https://www.findamasters.com/masters-degrees/c...    0.305071  \n",
       "9   https://www.findamasters.com/masters-degrees/c...    0.299051  \n",
       "10  https://www.findamasters.com/masters-degrees/c...    0.296599  \n",
       "11  https://www.findamasters.com/masters-degrees/c...    0.295198  \n",
       "12  https://www.findamasters.com/masters-degrees/c...    0.294579  \n",
       "13  https://www.findamasters.com/masters-degrees/c...    0.294348  \n",
       "14  https://www.findamasters.com/masters-degrees/c...    0.279512  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = 'advanced knowledge'\n",
    "query_result = execute_query_modified(query, inverted_index_tfidf, df_updated, df_tfidf, tfidf_vectorizer).head(15)\n",
    "query_result\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define a new score!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding a new Dataframe to our existing one to write a scoring function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qs_path = '2024 QS World University Rankings 1.1 (For qs.com).csv'\n",
    "qs_df = pd.read_csv(qs_path)\n",
    "qs_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matching the collumn names on dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'fees_USD' in dummy.columns:\n",
    "    # Replace 'fees' column in df_updated with 'fees_USD' column from dummy\n",
    "    df_updated['fees'] = dummy['fees_USD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_updated = df_updated.merge(qs_df, left_on='universityName', right_on='Institution Name', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping columns from df_updated\n",
    "columns_to_drop = ['Academic Reputation Rank', 'Employer Reputation Rank','Faculty Student Rank','Faculty Student Rank', 'Citations per Faculty Rank', 'International Faculty Rank', 'International Students Rank', 'International Research Network Rank', 'Employment Outcomes Rank',  'Sustainability Rank', 'Overall SCORE']\n",
    "df_updated = df_updated.drop(labels=columns_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_updated.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print all column names (factors) of the DataFrame\n",
    "print(df_updated.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we removed the unnecessery collumns and removed the Overal Score collumn (because we will define our own scoring function). Now lets start on scoring function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_score(document, query):\n",
    "    score = 0\n",
    "\n",
    "    # Weights for different components\n",
    "    academic_weight = 0.15\n",
    "    employer_weight = 0.15\n",
    "    international_faculty_weight = 0.1\n",
    "    international_students_weight = 0.1\n",
    "    citations_weight = 0.1\n",
    "    textual_relevance_weight = 0.4\n",
    "\n",
    "    # Academic and Employer Reputation\n",
    "    if not pd.isnull(document['Academic Reputation Score']):\n",
    "        score += float(document['Academic Reputation Score']) / 100 * academic_weight\n",
    "    if not pd.isnull(document['Employer Reputation Score']):\n",
    "        score += float(document['Employer Reputation Score']) / 100 * employer_weight\n",
    "\n",
    "    # International Faculty and Students Scores\n",
    "    if not pd.isnull(document['International Faculty Score']):\n",
    "        score += float(document['International Faculty Score']) / 100 * international_faculty_weight\n",
    "    if not pd.isnull(document['International Students Score']):\n",
    "        score += float(document['International Students Score']) / 100 * international_students_weight\n",
    "\n",
    "    # Citations per Faculty\n",
    "    if not pd.isnull(document['Citations per Faculty Score']):\n",
    "        score += float(document['Citations per Faculty Score']) / 100 * citations_weight\n",
    "\n",
    "    # Textual Relevance\n",
    "    query_terms = set(query.lower().split())\n",
    "    description_terms = set(document['description_lemmatized'].lower().split())\n",
    "    common_terms = query_terms.intersection(description_terms)\n",
    "    score += len(common_terms) / len(query_terms) * textual_relevance_weight\n",
    "\n",
    "    # Normalization based on the total weights\n",
    "    total_weight = academic_weight + employer_weight + international_faculty_weight + international_students_weight + citations_weight + textual_relevance_weight\n",
    "    normalized_score = (score / total_weight) * 100  # Normalized to be out of 100\n",
    "\n",
    "    return min(normalized_score, 100)  # Ensuring the score doesn't exceed 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-Creating the inverted index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to store word occurrences with row indices\n",
    "result_dict = {word: [] for word in vocabulary}\n",
    "\n",
    "# Iterate over rows to find occurrences\n",
    "i = 0\n",
    "for idx, description in enumerate(df_updated['description_lemmatized']):\n",
    "\n",
    "    # Handling NaN/float values\n",
    "    if isinstance(description, str):  \n",
    "        words = description.split()\n",
    "        for word in words:\n",
    "            if word in vocabulary:\n",
    "                result_dict[word].append(idx)\n",
    "    \n",
    "words_frequency = {}\n",
    "\n",
    "for index, word in vocabulary_dict.items():\n",
    "    if word in result_dict:\n",
    "        words_frequency[index] = result_dict[word]\n",
    "\n",
    "words_frequency\n",
    "\n",
    "# Create a DataFrame from the dictionary\n",
    "inverted_index = pd.DataFrame(list(result_dict.items()), columns=['word', 'documents_IDs'])\n",
    "inverted_index['documents_IDs'] = inverted_index['documents_IDs'].apply(lambda x: list(set(x)))\n",
    "inverted_index.to_csv('inverted_index.csv', index=False)\n",
    "inverted_index.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will add the similarity score calculation (using jaccard similarity) and sorting the master courses in our dataframe regarding on similarity scores and overall scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the preprocess_text function\n",
    "def preprocess_text(text):\n",
    "    \n",
    "    # Handling NaN/float values\n",
    "    if not isinstance(text, str):\n",
    "        return ''\n",
    "\n",
    "    # Converting the text to lower case\n",
    "    text = text.lower()\n",
    "\n",
    "    # Removing punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "    # Breaking the text into words(tokens)\n",
    "    words = nltk.word_tokenize(text)\n",
    "\n",
    "    # Removing stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "\n",
    "    # Stemming\n",
    "    stemmer = PorterStemmer()\n",
    "    words = [stemmer.stem(word) for word in words]\n",
    "\n",
    "    # Joining the list of words to form the processed text\n",
    "    processed_text = ' '.join(words)\n",
    "\n",
    "    return processed_text\n",
    "\n",
    "# Function to calculate Jaccard similarity score\n",
    "def calculate_jaccard_similarity(query_terms, document_terms):\n",
    "    intersection = query_terms.intersection(document_terms)\n",
    "    union = query_terms.union(document_terms)\n",
    "    if len(union) == 0:\n",
    "        return 0\n",
    "    return len(intersection) / len(union)\n",
    "\n",
    "# Execute_query function\n",
    "def execute_query(query, inverted_index, df):\n",
    "    # Apply text preprocessing to the query\n",
    "    processed_query = preprocess_text(query)\n",
    "    query_words = processed_query.split()\n",
    "\n",
    "    # Find document_IDs for each word in the query using the inverted index\n",
    "    result_document_ids = []\n",
    "    for word in query_words:\n",
    "        if word in inverted_index['word'].values:\n",
    "            # Retrieve and flatten the list of document IDs\n",
    "            word_document_ids = inverted_index.loc[inverted_index['word'] == word, 'documents_IDs'].explode().tolist()\n",
    "            result_document_ids.extend(word_document_ids)\n",
    "\n",
    "    # Remove duplicate document_IDs and sort\n",
    "    result_document_ids = sorted(set(result_document_ids))\n",
    "\n",
    "    # Retrieve the rows corresponding to the document_IDs\n",
    "    relevant_docs = df.loc[result_document_ids]\n",
    "\n",
    "    # Process the descriptions and calculate similarity scores\n",
    "    relevant_docs['processed_description'] = relevant_docs['description_lemmatized'].apply(preprocess_text)\n",
    "    query_terms_set = set(processed_query.split())\n",
    "    relevant_docs['similarity_score'] = relevant_docs['processed_description'].apply(\n",
    "        lambda doc: calculate_jaccard_similarity(query_terms_set, set(doc.split()))\n",
    "    )\n",
    "\n",
    "    # Calculate relevance scores for each document\n",
    "    relevant_docs['relevance_score'] = relevant_docs.apply(lambda doc: calculate_score(doc, query), axis=1)\n",
    "\n",
    "    # Sort documents first by relevance score, then by similarity score\n",
    "    sorted_results = relevant_docs.sort_values(by=['relevance_score', 'similarity_score'], ascending=[False, False])\n",
    "\n",
    "    # Filter out additional courses from the same university, keeping only the most relevant one\n",
    "    most_relevant_per_university = sorted_results.drop_duplicates(subset='universityName')\n",
    "\n",
    "    # Select specific columns for the final output\n",
    "    final_columns = ['courseName', 'universityName', 'description', 'url', 'fees_USD', 'city', 'similarity_score', 'relevance_score']\n",
    "    final_results = most_relevant_per_university[final_columns]\n",
    "\n",
    "    return final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_query = 'advanced knowledge'\n",
    "result = execute_query(sample_query, inverted_index, df_updated)\n",
    "print(f'Number of results: {len(result)}')\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Master's Degrees visualization map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get the coordinates and country of a list of cities\n",
    "def get_city_country_with_coordinates(cities):\n",
    "    # Dictionary to store cities and their coordinates and countries\n",
    "    city_country_coordinates = {}\n",
    "\n",
    "    for city in cities:\n",
    "        # Geolocator instance\n",
    "        geolocator = Nominatim(user_agent=\"my_geocoder\")\n",
    "        location = geolocator.geocode(city)\n",
    "\n",
    "        if location:\n",
    "            city_coordinates = (location.latitude, location.longitude)\n",
    "            country = location.address.split(\",\")[-1].strip()\n",
    "            city_country_coordinates[city] = (city_coordinates, country)\n",
    "\n",
    "        else:\n",
    "            # If the city is not found, set the coordinates to None\n",
    "            city_country_coordinates[city] = (None, \"\")\n",
    "        \n",
    "        time.sleep(1)\n",
    "\n",
    "    return city_country_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of all the cities\n",
    "cities = set(df_updated['city'].values)\n",
    "# dictionary of cities and their coordinates and countries\n",
    "city_country_coordinates = get_city_country_with_coordinates(cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Coordinates</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Groningen</td>\n",
       "      <td>(53.2190652, 6.5680077)</td>\n",
       "      <td>Nederland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kingston</td>\n",
       "      <td>(17.9712148, -76.7928128)</td>\n",
       "      <td>Jamaica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cambridge</td>\n",
       "      <td>(52.2055314, 0.1186637)</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Heidelberg</td>\n",
       "      <td>(49.4093582, 8.694724)</td>\n",
       "      <td>Deutschland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brussels</td>\n",
       "      <td>(50.8550018, 4.3512333761166175)</td>\n",
       "      <td>België / Belgique / Belgien</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         City                       Coordinates                      Country\n",
       "0   Groningen           (53.2190652, 6.5680077)                    Nederland\n",
       "1    Kingston         (17.9712148, -76.7928128)                      Jamaica\n",
       "2   Cambridge           (52.2055314, 0.1186637)               United Kingdom\n",
       "3  Heidelberg            (49.4093582, 8.694724)                  Deutschland\n",
       "4    Brussels  (50.8550018, 4.3512333761166175)  België / Belgique / Belgien"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame\n",
    "df_city_country_coordinates = pd.DataFrame(list(city_country_coordinates.items()), columns=['City', 'Data'])\n",
    "\n",
    "# Split the 'Data' column into 'Coordinates' and 'Country'\n",
    "df_city_country_coordinates[['Coordinates', 'Country']] = pd.DataFrame(df_city_country_coordinates['Data'].tolist(),\n",
    "                                                                        index=df_city_country_coordinates.index)\n",
    "\n",
    "# Drop the original 'Data' column\n",
    "df_city_country_coordinates = df_city_country_coordinates.drop('Data', axis=1)\n",
    "\n",
    "df_city_country_coordinates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_map(df_city_country_coordinates, query_result):\n",
    "    # Create a map centered around the first city in the coordinates dataframe\n",
    "    map_center = df_city_country_coordinates['Coordinates'].iloc[0]\n",
    "    my_map = folium.Map(location=map_center, zoom_start=2)\n",
    "\n",
    "    # Add markers for each city in the query result dataframe\n",
    "    for city_info in query_result['city'].unique():\n",
    "        # Get the coordinates and country for the current city\n",
    "        city_data = df_city_country_coordinates.loc[\n",
    "            df_city_country_coordinates['City'] == city_info]\n",
    "        city_coordinates = city_data['Coordinates'].values[0]\n",
    "        city_country = city_data['Country'].values[0]\n",
    "\n",
    "        # Get master courses information for the current city\n",
    "        city_courses = query_result[query_result['city'] == city_info]\n",
    "\n",
    "        # Create a label for the marker with master courses information\n",
    "        label = f'<link rel=\"stylesheet\" type=\"text/css\" href=\"styles.css\">'  # Link to external CSS\n",
    "        label += f'<h4 style=\"text-align:center;\">{city_info}, {city_country}</h4><br>'\n",
    "        for index, course in city_courses.iterrows():\n",
    "            label += f'<p><b>Course:</b> {course[\"courseName\"]}</p>'\n",
    "            label += f'<p><b>University:</b> {course[\"universityName\"]}</p>'\n",
    "            \n",
    "            # Separate fees information\n",
    "            fees_text = f'<p><b>Tuition in USD:</b> ${course[\"fees_USD\"]:.2f}</p>' if course[\"fees_USD\"] != 0.00 else \\\n",
    "                        f'<p><b>Tuition in USD:</b> Visit the website</p>'\n",
    "            label += f'{fees_text}'\n",
    "\n",
    "            # Separate URL information\n",
    "            url_text = f'<p><b>URL:</b> <a href=\"{course[\"url\"]}\" target=\"_blank\">{course[\"url\"]}</a></p>'\n",
    "            label += f'{url_text}<br><br>'\n",
    "\n",
    "        # Create and add the marker to the map\n",
    "        iframe = IFrame(html=label, width=500, height=500)\n",
    "        popup = folium.Popup(iframe, max_width=500)\n",
    "        folium.Marker(location=city_coordinates, popup=popup).add_to(my_map)\n",
    "\n",
    "    # Display the map in the notebook\n",
    "    display(my_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><span style=\"color:#565656\">Make this Notebook Trusted to load map: File -> Trust Notebook</span><iframe srcdoc=\"&lt;!DOCTYPE html&gt;\n",
       "&lt;html&gt;\n",
       "&lt;head&gt;\n",
       "    \n",
       "    &lt;meta http-equiv=&quot;content-type&quot; content=&quot;text/html; charset=UTF-8&quot; /&gt;\n",
       "    \n",
       "        &lt;script&gt;\n",
       "            L_NO_TOUCH = false;\n",
       "            L_DISABLE_3D = false;\n",
       "        &lt;/script&gt;\n",
       "    \n",
       "    &lt;style&gt;html, body {width: 100%;height: 100%;margin: 0;padding: 0;}&lt;/style&gt;\n",
       "    &lt;style&gt;#map {position:absolute;top:0;bottom:0;right:0;left:0;}&lt;/style&gt;\n",
       "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://code.jquery.com/jquery-3.7.1.min.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/js/bootstrap.bundle.min.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/css/bootstrap.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://netdna.bootstrapcdn.com/bootstrap/3.0.0/css/bootstrap.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.2.0/css/all.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/gh/python-visualization/folium/folium/templates/leaflet.awesome.rotate.min.css&quot;/&gt;\n",
       "    \n",
       "            &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width,\n",
       "                initial-scale=1.0, maximum-scale=1.0, user-scalable=no&quot; /&gt;\n",
       "            &lt;style&gt;\n",
       "                #map_8637fccdcb7edd1dd1dcbe4a9ec85b0b {\n",
       "                    position: relative;\n",
       "                    width: 100.0%;\n",
       "                    height: 100.0%;\n",
       "                    left: 0.0%;\n",
       "                    top: 0.0%;\n",
       "                }\n",
       "                .leaflet-container { font-size: 1rem; }\n",
       "            &lt;/style&gt;\n",
       "        \n",
       "&lt;/head&gt;\n",
       "&lt;body&gt;\n",
       "    \n",
       "    \n",
       "            &lt;div class=&quot;folium-map&quot; id=&quot;map_8637fccdcb7edd1dd1dcbe4a9ec85b0b&quot; &gt;&lt;/div&gt;\n",
       "        \n",
       "&lt;/body&gt;\n",
       "&lt;script&gt;\n",
       "    \n",
       "    \n",
       "            var map_8637fccdcb7edd1dd1dcbe4a9ec85b0b = L.map(\n",
       "                &quot;map_8637fccdcb7edd1dd1dcbe4a9ec85b0b&quot;,\n",
       "                {\n",
       "                    center: [53.2190652, 6.5680077],\n",
       "                    crs: L.CRS.EPSG3857,\n",
       "                    zoom: 2,\n",
       "                    zoomControl: true,\n",
       "                    preferCanvas: false,\n",
       "                }\n",
       "            );\n",
       "\n",
       "            \n",
       "\n",
       "        \n",
       "    \n",
       "            var tile_layer_4224ff3ebf5cd51528c067ac2ea69886 = L.tileLayer(\n",
       "                &quot;https://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png&quot;,\n",
       "                {&quot;attribution&quot;: &quot;Data by \\u0026copy; \\u003ca target=\\&quot;_blank\\&quot; href=\\&quot;http://openstreetmap.org\\&quot;\\u003eOpenStreetMap\\u003c/a\\u003e, under \\u003ca target=\\&quot;_blank\\&quot; href=\\&quot;http://www.openstreetmap.org/copyright\\&quot;\\u003eODbL\\u003c/a\\u003e.&quot;, &quot;detectRetina&quot;: false, &quot;maxNativeZoom&quot;: 18, &quot;maxZoom&quot;: 18, &quot;minZoom&quot;: 0, &quot;noWrap&quot;: false, &quot;opacity&quot;: 1, &quot;subdomains&quot;: &quot;abc&quot;, &quot;tms&quot;: false}\n",
       "            );\n",
       "        \n",
       "    \n",
       "                tile_layer_4224ff3ebf5cd51528c067ac2ea69886.addTo(map_8637fccdcb7edd1dd1dcbe4a9ec85b0b);\n",
       "    \n",
       "            var marker_1ae0c40f2628c124c3c5ee62c2746b08 = L.marker(\n",
       "                [51.5074456, -0.1277653],\n",
       "                {}\n",
       "            ).addTo(map_8637fccdcb7edd1dd1dcbe4a9ec85b0b);\n",
       "        \n",
       "    \n",
       "        var popup_b85e349cc1beb12d51c804d0ee41071e = L.popup({&quot;maxWidth&quot;: 500});\n",
       "\n",
       "        \n",
       "            \n",
       "                var i_frame_99c9a13bbc3e605bb1e8126ba3e321dc = $(`&lt;iframe src=&quot;data:text/html;charset=utf-8;base64,CiAgICA8bGluayByZWw9InN0eWxlc2hlZXQiIHR5cGU9InRleHQvY3NzIiBocmVmPSJzdHlsZXMuY3NzIj48aDQgc3R5bGU9InRleHQtYWxpZ246Y2VudGVyOyI+TG9uZG9uLCBVbml0ZWQgS2luZ2RvbTwvaDQ+PGJyPjxwPjxiPkNvdXJzZTo8L2I+IEFkdmFuY2VkIENvbXB1dGluZyBNU2M8L3A+PHA+PGI+VW5pdmVyc2l0eTo8L2I+IEtpbmfigJlzIENvbGxlZ2UgTG9uZG9uPC9wPjxwPjxiPlR1aXRpb24gaW4gVVNEOjwvYj4gVmlzaXQgdGhlIHdlYnNpdGU8L3A+PHA+PGI+VVJMOjwvYj4gPGEgaHJlZj0iaHR0cHM6Ly93d3cuZmluZGFtYXN0ZXJzLmNvbS9tYXN0ZXJzLWRlZ3JlZXMvY291cnNlL2FkdmFuY2VkLWNvbXB1dGluZy1tc2MvP2kxMzJkMzkwNWMyMzUyNCIgdGFyZ2V0PSJfYmxhbmsiPmh0dHBzOi8vd3d3LmZpbmRhbWFzdGVycy5jb20vbWFzdGVycy1kZWdyZWVzL2NvdXJzZS9hZHZhbmNlZC1jb21wdXRpbmctbXNjLz9pMTMyZDM5MDVjMjM1MjQ8L2E+PC9wPjxicj48YnI+&quot; width=&quot;500&quot; style=&quot;border:none !important;&quot; height=&quot;500&quot;&gt;&lt;/iframe&gt;`)[0];\n",
       "                popup_b85e349cc1beb12d51c804d0ee41071e.setContent(i_frame_99c9a13bbc3e605bb1e8126ba3e321dc);\n",
       "            \n",
       "        \n",
       "\n",
       "        marker_1ae0c40f2628c124c3c5ee62c2746b08.bindPopup(popup_b85e349cc1beb12d51c804d0ee41071e)\n",
       "        ;\n",
       "\n",
       "        \n",
       "    \n",
       "    \n",
       "            var marker_d787afac6e9122fe4f5d76f3e6c28e27 = L.marker(\n",
       "                [52.23433665, -0.9028072768185829],\n",
       "                {}\n",
       "            ).addTo(map_8637fccdcb7edd1dd1dcbe4a9ec85b0b);\n",
       "        \n",
       "    \n",
       "        var popup_6e663645554d10949cecfdcf10615df1 = L.popup({&quot;maxWidth&quot;: 500});\n",
       "\n",
       "        \n",
       "            \n",
       "                var i_frame_ede9caa0c927f9c31f8882c28cf2e2b9 = $(`&lt;iframe src=&quot;data:text/html;charset=utf-8;base64,CiAgICA8bGluayByZWw9InN0eWxlc2hlZXQiIHR5cGU9InRleHQvY3NzIiBocmVmPSJzdHlsZXMuY3NzIj48aDQgc3R5bGU9InRleHQtYWxpZ246Y2VudGVyOyI+Tm9ydGhhbXB0b24sIFVuaXRlZCBLaW5nZG9tPC9oND48YnI+PHA+PGI+Q291cnNlOjwvYj4gQWR2YW5jaW5nIFByYWN0aWNlIC0gTVNjPC9wPjxwPjxiPlVuaXZlcnNpdHk6PC9iPiBVbml2ZXJzaXR5IG9mIE5vcnRoYW1wdG9uPC9wPjxwPjxiPlR1aXRpb24gaW4gVVNEOjwvYj4gVmlzaXQgdGhlIHdlYnNpdGU8L3A+PHA+PGI+VVJMOjwvYj4gPGEgaHJlZj0iaHR0cHM6Ly93d3cuZmluZGFtYXN0ZXJzLmNvbS9tYXN0ZXJzLWRlZ3JlZXMvY291cnNlL2FkdmFuY2luZy1wcmFjdGljZS1tc2MvP2kzMzdkMTc3NGM1Nzc1OSIgdGFyZ2V0PSJfYmxhbmsiPmh0dHBzOi8vd3d3LmZpbmRhbWFzdGVycy5jb20vbWFzdGVycy1kZWdyZWVzL2NvdXJzZS9hZHZhbmNpbmctcHJhY3RpY2UtbXNjLz9pMzM3ZDE3NzRjNTc3NTk8L2E+PC9wPjxicj48YnI+PHA+PGI+Q291cnNlOjwvYj4gQWR2YW5jZWQgQ2xpbmljYWwgUHJhY3RpY2UgLSBNU2M8L3A+PHA+PGI+VW5pdmVyc2l0eTo8L2I+IFVuaXZlcnNpdHkgb2YgTm9ydGhhbXB0b248L3A+PHA+PGI+VHVpdGlvbiBpbiBVU0Q6PC9iPiBWaXNpdCB0aGUgd2Vic2l0ZTwvcD48cD48Yj5VUkw6PC9iPiA8YSBocmVmPSJodHRwczovL3d3dy5maW5kYW1hc3RlcnMuY29tL21hc3RlcnMtZGVncmVlcy9jb3Vyc2UvYWR2YW5jZWQtY2xpbmljYWwtcHJhY3RpY2UtbXNjLz9pMzM3ZDE3NzRjNjI2NjciIHRhcmdldD0iX2JsYW5rIj5odHRwczovL3d3dy5maW5kYW1hc3RlcnMuY29tL21hc3RlcnMtZGVncmVlcy9jb3Vyc2UvYWR2YW5jZWQtY2xpbmljYWwtcHJhY3RpY2UtbXNjLz9pMzM3ZDE3NzRjNjI2Njc8L2E+PC9wPjxicj48YnI+&quot; width=&quot;500&quot; style=&quot;border:none !important;&quot; height=&quot;500&quot;&gt;&lt;/iframe&gt;`)[0];\n",
       "                popup_6e663645554d10949cecfdcf10615df1.setContent(i_frame_ede9caa0c927f9c31f8882c28cf2e2b9);\n",
       "            \n",
       "        \n",
       "\n",
       "        marker_d787afac6e9122fe4f5d76f3e6c28e27.bindPopup(popup_6e663645554d10949cecfdcf10615df1)\n",
       "        ;\n",
       "\n",
       "        \n",
       "    \n",
       "    \n",
       "            var marker_779b6923298558d0c0b59230d31e43a5 = L.marker(\n",
       "                [51.4816546, -3.1791934],\n",
       "                {}\n",
       "            ).addTo(map_8637fccdcb7edd1dd1dcbe4a9ec85b0b);\n",
       "        \n",
       "    \n",
       "        var popup_b7ca21af0a70b501b9105a41d95c23f9 = L.popup({&quot;maxWidth&quot;: 500});\n",
       "\n",
       "        \n",
       "            \n",
       "                var i_frame_a198e30286663180860ff3d5c447aef7 = $(`&lt;iframe src=&quot;data:text/html;charset=utf-8;base64,CiAgICA8bGluayByZWw9InN0eWxlc2hlZXQiIHR5cGU9InRleHQvY3NzIiBocmVmPSJzdHlsZXMuY3NzIj48aDQgc3R5bGU9InRleHQtYWxpZ246Y2VudGVyOyI+Q2FyZGlmZiwgVW5pdGVkIEtpbmdkb208L2g0Pjxicj48cD48Yj5Db3Vyc2U6PC9iPiBBZHZhbmNlZCBIZWFsdGhjYXJlIFByYWN0aWNlIC0gTVNjPC9wPjxwPjxiPlVuaXZlcnNpdHk6PC9iPiBDYXJkaWZmIFVuaXZlcnNpdHk8L3A+PHA+PGI+VHVpdGlvbiBpbiBVU0Q6PC9iPiBWaXNpdCB0aGUgd2Vic2l0ZTwvcD48cD48Yj5VUkw6PC9iPiA8YSBocmVmPSJodHRwczovL3d3dy5maW5kYW1hc3RlcnMuY29tL21hc3RlcnMtZGVncmVlcy9jb3Vyc2UvYWR2YW5jZWQtaGVhbHRoY2FyZS1wcmFjdGljZS1tc2MvP2kzM2Q0NzM2YzY3MDYyIiB0YXJnZXQ9Il9ibGFuayI+aHR0cHM6Ly93d3cuZmluZGFtYXN0ZXJzLmNvbS9tYXN0ZXJzLWRlZ3JlZXMvY291cnNlL2FkdmFuY2VkLWhlYWx0aGNhcmUtcHJhY3RpY2UtbXNjLz9pMzNkNDczNmM2NzA2MjwvYT48L3A+PGJyPjxicj48cD48Yj5Db3Vyc2U6PC9iPiBBZHZhbmNlZCBDb21wdXRlciBTY2llbmNlIC0gTVNjL1BnRC9QZ0M8L3A+PHA+PGI+VW5pdmVyc2l0eTo8L2I+IENhcmRpZmYgTWV0cm9wb2xpdGFuIFVuaXZlcnNpdHk8L3A+PHA+PGI+VHVpdGlvbiBpbiBVU0Q6PC9iPiBWaXNpdCB0aGUgd2Vic2l0ZTwvcD48cD48Yj5VUkw6PC9iPiA8YSBocmVmPSJodHRwczovL3d3dy5maW5kYW1hc3RlcnMuY29tL21hc3RlcnMtZGVncmVlcy9jb3Vyc2UvYWR2YW5jZWQtY29tcHV0ZXItc2NpZW5jZS1tc2MtcGdkLXBnYy8/aTM2NmQ4MjQzYzU3NzMzIiB0YXJnZXQ9Il9ibGFuayI+aHR0cHM6Ly93d3cuZmluZGFtYXN0ZXJzLmNvbS9tYXN0ZXJzLWRlZ3JlZXMvY291cnNlL2FkdmFuY2VkLWNvbXB1dGVyLXNjaWVuY2UtbXNjLXBnZC1wZ2MvP2kzNjZkODI0M2M1NzczMzwvYT48L3A+PGJyPjxicj4=&quot; width=&quot;500&quot; style=&quot;border:none !important;&quot; height=&quot;500&quot;&gt;&lt;/iframe&gt;`)[0];\n",
       "                popup_b7ca21af0a70b501b9105a41d95c23f9.setContent(i_frame_a198e30286663180860ff3d5c447aef7);\n",
       "            \n",
       "        \n",
       "\n",
       "        marker_779b6923298558d0c0b59230d31e43a5.bindPopup(popup_b7ca21af0a70b501b9105a41d95c23f9)\n",
       "        ;\n",
       "\n",
       "        \n",
       "    \n",
       "    \n",
       "            var marker_7e8c03560d0d490770cf42b6c7208959 = L.marker(\n",
       "                [51.2800275, 1.0802533],\n",
       "                {}\n",
       "            ).addTo(map_8637fccdcb7edd1dd1dcbe4a9ec85b0b);\n",
       "        \n",
       "    \n",
       "        var popup_87af740bec14e1dd758c8f0e23023628 = L.popup({&quot;maxWidth&quot;: 500});\n",
       "\n",
       "        \n",
       "            \n",
       "                var i_frame_1d994e840952c692ae21686494a04e78 = $(`&lt;iframe src=&quot;data:text/html;charset=utf-8;base64,CiAgICA8bGluayByZWw9InN0eWxlc2hlZXQiIHR5cGU9InRleHQvY3NzIiBocmVmPSJzdHlsZXMuY3NzIj48aDQgc3R5bGU9InRleHQtYWxpZ246Y2VudGVyOyI+Q2FudGVyYnVyeSwgVW5pdGVkIEtpbmdkb208L2g0Pjxicj48cD48Yj5Db3Vyc2U6PC9iPiBBZHZhbmNlZCBDbGluaWNhbCBQcmFjdGljZSAtIE1TYzwvcD48cD48Yj5Vbml2ZXJzaXR5OjwvYj4gQ2FudGVyYnVyeSBDaHJpc3QgQ2h1cmNoIFVuaXZlcnNpdHk8L3A+PHA+PGI+VHVpdGlvbiBpbiBVU0Q6PC9iPiAkMTI4OS4wODwvcD48cD48Yj5VUkw6PC9iPiA8YSBocmVmPSJodHRwczovL3d3dy5maW5kYW1hc3RlcnMuY29tL21hc3RlcnMtZGVncmVlcy9jb3Vyc2UvYWR2YW5jZWQtY2xpbmljYWwtcHJhY3RpY2UtbXNjLz9pMzJkMjcxMmM1NzAwMiIgdGFyZ2V0PSJfYmxhbmsiPmh0dHBzOi8vd3d3LmZpbmRhbWFzdGVycy5jb20vbWFzdGVycy1kZWdyZWVzL2NvdXJzZS9hZHZhbmNlZC1jbGluaWNhbC1wcmFjdGljZS1tc2MvP2kzMmQyNzEyYzU3MDAyPC9hPjwvcD48YnI+PGJyPg==&quot; width=&quot;500&quot; style=&quot;border:none !important;&quot; height=&quot;500&quot;&gt;&lt;/iframe&gt;`)[0];\n",
       "                popup_87af740bec14e1dd758c8f0e23023628.setContent(i_frame_1d994e840952c692ae21686494a04e78);\n",
       "            \n",
       "        \n",
       "\n",
       "        marker_7e8c03560d0d490770cf42b6c7208959.bindPopup(popup_87af740bec14e1dd758c8f0e23023628)\n",
       "        ;\n",
       "\n",
       "        \n",
       "    \n",
       "    \n",
       "            var marker_5c3a7cf6aaf2083d3ead87f468bd8f2e = L.marker(\n",
       "                [53.7974185, -1.5437941],\n",
       "                {}\n",
       "            ).addTo(map_8637fccdcb7edd1dd1dcbe4a9ec85b0b);\n",
       "        \n",
       "    \n",
       "        var popup_4081b46295e14c8ade1c7c9765b47b65 = L.popup({&quot;maxWidth&quot;: 500});\n",
       "\n",
       "        \n",
       "            \n",
       "                var i_frame_8ecb2aef325bec1bee5787618bde7166 = $(`&lt;iframe src=&quot;data:text/html;charset=utf-8;base64,CiAgICA8bGluayByZWw9InN0eWxlc2hlZXQiIHR5cGU9InRleHQvY3NzIiBocmVmPSJzdHlsZXMuY3NzIj48aDQgc3R5bGU9InRleHQtYWxpZ246Y2VudGVyOyI+TGVlZHMsIFVuaXRlZCBLaW5nZG9tPC9oND48YnI+PHA+PGI+Q291cnNlOjwvYj4gQWR2YW5jZWQgTWVjaGFuaWNhbCBFbmdpbmVlcmluZyAtIE1TYyAoRW5nKTwvcD48cD48Yj5Vbml2ZXJzaXR5OjwvYj4gVW5pdmVyc2l0eSBvZiBMZWVkczwvcD48cD48Yj5UdWl0aW9uIGluIFVTRDo8L2I+ICQyNDgyMC43NzwvcD48cD48Yj5VUkw6PC9iPiA8YSBocmVmPSJodHRwczovL3d3dy5maW5kYW1hc3RlcnMuY29tL21hc3RlcnMtZGVncmVlcy9jb3Vyc2UvYWR2YW5jZWQtbWVjaGFuaWNhbC1lbmdpbmVlcmluZy1tc2MtZW5nLz9pMzIxZDEwMDJjMTIzMjciIHRhcmdldD0iX2JsYW5rIj5odHRwczovL3d3dy5maW5kYW1hc3RlcnMuY29tL21hc3RlcnMtZGVncmVlcy9jb3Vyc2UvYWR2YW5jZWQtbWVjaGFuaWNhbC1lbmdpbmVlcmluZy1tc2MtZW5nLz9pMzIxZDEwMDJjMTIzMjc8L2E+PC9wPjxicj48YnI+&quot; width=&quot;500&quot; style=&quot;border:none !important;&quot; height=&quot;500&quot;&gt;&lt;/iframe&gt;`)[0];\n",
       "                popup_4081b46295e14c8ade1c7c9765b47b65.setContent(i_frame_8ecb2aef325bec1bee5787618bde7166);\n",
       "            \n",
       "        \n",
       "\n",
       "        marker_5c3a7cf6aaf2083d3ead87f468bd8f2e.bindPopup(popup_4081b46295e14c8ade1c7c9765b47b65)\n",
       "        ;\n",
       "\n",
       "        \n",
       "    \n",
       "    \n",
       "            var marker_6c7c38c8cf4da57041d8d8a992c43bf1 = L.marker(\n",
       "                [53.7944229, -1.7519186],\n",
       "                {}\n",
       "            ).addTo(map_8637fccdcb7edd1dd1dcbe4a9ec85b0b);\n",
       "        \n",
       "    \n",
       "        var popup_3caf6a26a3918c4c713e690a8225d882 = L.popup({&quot;maxWidth&quot;: 500});\n",
       "\n",
       "        \n",
       "            \n",
       "                var i_frame_d300bafb76610507f8acc89c96146f70 = $(`&lt;iframe src=&quot;data:text/html;charset=utf-8;base64,CiAgICA8bGluayByZWw9InN0eWxlc2hlZXQiIHR5cGU9InRleHQvY3NzIiBocmVmPSJzdHlsZXMuY3NzIj48aDQgc3R5bGU9InRleHQtYWxpZ246Y2VudGVyOyI+QnJhZGZvcmQsIFVuaXRlZCBLaW5nZG9tPC9oND48YnI+PHA+PGI+Q291cnNlOjwvYj4gQWR2YW5jZWQgQmlvbWVkaWNhbCBFbmdpbmVlcmluZyAtIE1TYzwvcD48cD48Yj5Vbml2ZXJzaXR5OjwvYj4gVW5pdmVyc2l0eSBvZiBCcmFkZm9yZDwvcD48cD48Yj5UdWl0aW9uIGluIFVTRDo8L2I+IFZpc2l0IHRoZSB3ZWJzaXRlPC9wPjxwPjxiPlVSTDo8L2I+IDxhIGhyZWY9Imh0dHBzOi8vd3d3LmZpbmRhbWFzdGVycy5jb20vbWFzdGVycy1kZWdyZWVzL2NvdXJzZS9hZHZhbmNlZC1iaW9tZWRpY2FsLWVuZ2luZWVyaW5nLW1zYy8/aTI4NWQ3NTY1YzUyODM5IiB0YXJnZXQ9Il9ibGFuayI+aHR0cHM6Ly93d3cuZmluZGFtYXN0ZXJzLmNvbS9tYXN0ZXJzLWRlZ3JlZXMvY291cnNlL2FkdmFuY2VkLWJpb21lZGljYWwtZW5naW5lZXJpbmctbXNjLz9pMjg1ZDc1NjVjNTI4Mzk8L2E+PC9wPjxicj48YnI+&quot; width=&quot;500&quot; style=&quot;border:none !important;&quot; height=&quot;500&quot;&gt;&lt;/iframe&gt;`)[0];\n",
       "                popup_3caf6a26a3918c4c713e690a8225d882.setContent(i_frame_d300bafb76610507f8acc89c96146f70);\n",
       "            \n",
       "        \n",
       "\n",
       "        marker_6c7c38c8cf4da57041d8d8a992c43bf1.bindPopup(popup_3caf6a26a3918c4c713e690a8225d882)\n",
       "        ;\n",
       "\n",
       "        \n",
       "    \n",
       "    \n",
       "            var marker_9e5f0083617790e26dabd8a27aa0a696 = L.marker(\n",
       "                [51.8653705, -2.2458192],\n",
       "                {}\n",
       "            ).addTo(map_8637fccdcb7edd1dd1dcbe4a9ec85b0b);\n",
       "        \n",
       "    \n",
       "        var popup_056936965c08a119cd4b8399b4d84e65 = L.popup({&quot;maxWidth&quot;: 500});\n",
       "\n",
       "        \n",
       "            \n",
       "                var i_frame_5df69d9892da80a6201c5f529814b6b6 = $(`&lt;iframe src=&quot;data:text/html;charset=utf-8;base64,CiAgICA8bGluayByZWw9InN0eWxlc2hlZXQiIHR5cGU9InRleHQvY3NzIiBocmVmPSJzdHlsZXMuY3NzIj48aDQgc3R5bGU9InRleHQtYWxpZ246Y2VudGVyOyI+R2xvdWNlc3RlciwgVW5pdGVkIEtpbmdkb208L2g0Pjxicj48cD48Yj5Db3Vyc2U6PC9iPiBBZHZhbmNlZCBQcm9mZXNzaW9uYWwgUHJhY3RpY2UgKE1TYyk8L3A+PHA+PGI+VW5pdmVyc2l0eTo8L2I+IFVuaXZlcnNpdHkgb2YgR2xvdWNlc3RlcnNoaXJlPC9wPjxwPjxiPlR1aXRpb24gaW4gVVNEOjwvYj4gVmlzaXQgdGhlIHdlYnNpdGU8L3A+PHA+PGI+VVJMOjwvYj4gPGEgaHJlZj0iaHR0cHM6Ly93d3cuZmluZGFtYXN0ZXJzLmNvbS9tYXN0ZXJzLWRlZ3JlZXMvY291cnNlL2FkdmFuY2VkLXByb2Zlc3Npb25hbC1wcmFjdGljZS1tc2MvP2kzMDhkMTE3M2M1NTE4NiIgdGFyZ2V0PSJfYmxhbmsiPmh0dHBzOi8vd3d3LmZpbmRhbWFzdGVycy5jb20vbWFzdGVycy1kZWdyZWVzL2NvdXJzZS9hZHZhbmNlZC1wcm9mZXNzaW9uYWwtcHJhY3RpY2UtbXNjLz9pMzA4ZDExNzNjNTUxODY8L2E+PC9wPjxicj48YnI+&quot; width=&quot;500&quot; style=&quot;border:none !important;&quot; height=&quot;500&quot;&gt;&lt;/iframe&gt;`)[0];\n",
       "                popup_056936965c08a119cd4b8399b4d84e65.setContent(i_frame_5df69d9892da80a6201c5f529814b6b6);\n",
       "            \n",
       "        \n",
       "\n",
       "        marker_9e5f0083617790e26dabd8a27aa0a696.bindPopup(popup_056936965c08a119cd4b8399b4d84e65)\n",
       "        ;\n",
       "\n",
       "        \n",
       "    \n",
       "    \n",
       "            var marker_c954f5e1cd268357c8e1387b19077676 = L.marker(\n",
       "                [55.861155, -4.2501687],\n",
       "                {}\n",
       "            ).addTo(map_8637fccdcb7edd1dd1dcbe4a9ec85b0b);\n",
       "        \n",
       "    \n",
       "        var popup_999c11466b7a1d8fd7e81239425ed39a = L.popup({&quot;maxWidth&quot;: 500});\n",
       "\n",
       "        \n",
       "            \n",
       "                var i_frame_5e901430903f7086a9ffc773d9619ef8 = $(`&lt;iframe src=&quot;data:text/html;charset=utf-8;base64,CiAgICA8bGluayByZWw9InN0eWxlc2hlZXQiIHR5cGU9InRleHQvY3NzIiBocmVmPSJzdHlsZXMuY3NzIj48aDQgc3R5bGU9InRleHQtYWxpZ246Y2VudGVyOyI+R2xhc2dvdywgVW5pdGVkIEtpbmdkb208L2g0Pjxicj48cD48Yj5Db3Vyc2U6PC9iPiBBZHZhbmNlZCBDb21wdXRpbmcgLSBNU2M8L3A+PHA+PGI+VW5pdmVyc2l0eTo8L2I+IFVuaXZlcnNpdHkgb2YgdGhlIFdlc3Qgb2YgU2NvdGxhbmQ8L3A+PHA+PGI+VHVpdGlvbiBpbiBVU0Q6PC9iPiBWaXNpdCB0aGUgd2Vic2l0ZTwvcD48cD48Yj5VUkw6PC9iPiA8YSBocmVmPSJodHRwczovL3d3dy5maW5kYW1hc3RlcnMuY29tL21hc3RlcnMtZGVncmVlcy9jb3Vyc2UvYWR2YW5jZWQtY29tcHV0aW5nLW1zYy8/aTM2MGQ2NzQ1YzUyMzc0IiB0YXJnZXQ9Il9ibGFuayI+aHR0cHM6Ly93d3cuZmluZGFtYXN0ZXJzLmNvbS9tYXN0ZXJzLWRlZ3JlZXMvY291cnNlL2FkdmFuY2VkLWNvbXB1dGluZy1tc2MvP2kzNjBkNjc0NWM1MjM3NDwvYT48L3A+PGJyPjxicj4=&quot; width=&quot;500&quot; style=&quot;border:none !important;&quot; height=&quot;500&quot;&gt;&lt;/iframe&gt;`)[0];\n",
       "                popup_999c11466b7a1d8fd7e81239425ed39a.setContent(i_frame_5e901430903f7086a9ffc773d9619ef8);\n",
       "            \n",
       "        \n",
       "\n",
       "        marker_c954f5e1cd268357c8e1387b19077676.bindPopup(popup_999c11466b7a1d8fd7e81239425ed39a)\n",
       "        ;\n",
       "\n",
       "        \n",
       "    \n",
       "    \n",
       "            var marker_4106da680db5910dddb51c1b4ad50749 = L.marker(\n",
       "                [44.8016255, -68.7713289],\n",
       "                {}\n",
       "            ).addTo(map_8637fccdcb7edd1dd1dcbe4a9ec85b0b);\n",
       "        \n",
       "    \n",
       "        var popup_a6a570c7fe30bed82a8c44eed715e9f2 = L.popup({&quot;maxWidth&quot;: 500});\n",
       "\n",
       "        \n",
       "            \n",
       "                var i_frame_a8effd373547084620741d8c0aeac531 = $(`&lt;iframe src=&quot;data:text/html;charset=utf-8;base64,CiAgICA8bGluayByZWw9InN0eWxlc2hlZXQiIHR5cGU9InRleHQvY3NzIiBocmVmPSJzdHlsZXMuY3NzIj48aDQgc3R5bGU9InRleHQtYWxpZ246Y2VudGVyOyI+QmFuZ29yLCBVbml0ZWQgU3RhdGVzPC9oND48YnI+PHA+PGI+Q291cnNlOjwvYj4gQWR2YW5jZWQgQ2xpbmljYWwgUHJhY3RpY2UgKEFIUCkgLSBNU2MvUEdEaXAvUEdDZXJ0PC9wPjxwPjxiPlVuaXZlcnNpdHk6PC9iPiBCYW5nb3IgVW5pdmVyc2l0eTwvcD48cD48Yj5UdWl0aW9uIGluIFVTRDo8L2I+IFZpc2l0IHRoZSB3ZWJzaXRlPC9wPjxwPjxiPlVSTDo8L2I+IDxhIGhyZWY9Imh0dHBzOi8vd3d3LmZpbmRhbWFzdGVycy5jb20vbWFzdGVycy1kZWdyZWVzL2NvdXJzZS9hZHZhbmNlZC1jbGluaWNhbC1wcmFjdGljZS1haHAtbXNjLXBnZGlwLXBnY2VydC8/aTEzZDgwMDhjMzk0NDkiIHRhcmdldD0iX2JsYW5rIj5odHRwczovL3d3dy5maW5kYW1hc3RlcnMuY29tL21hc3RlcnMtZGVncmVlcy9jb3Vyc2UvYWR2YW5jZWQtY2xpbmljYWwtcHJhY3RpY2UtYWhwLW1zYy1wZ2RpcC1wZ2NlcnQvP2kxM2Q4MDA4YzM5NDQ5PC9hPjwvcD48YnI+PGJyPg==&quot; width=&quot;500&quot; style=&quot;border:none !important;&quot; height=&quot;500&quot;&gt;&lt;/iframe&gt;`)[0];\n",
       "                popup_a6a570c7fe30bed82a8c44eed715e9f2.setContent(i_frame_a8effd373547084620741d8c0aeac531);\n",
       "            \n",
       "        \n",
       "\n",
       "        marker_4106da680db5910dddb51c1b4ad50749.bindPopup(popup_a6a570c7fe30bed82a8c44eed715e9f2)\n",
       "        ;\n",
       "\n",
       "        \n",
       "    \n",
       "    \n",
       "            var marker_5042be753726871ff1529851749dacdd = L.marker(\n",
       "                [54.9058512, -1.3828727],\n",
       "                {}\n",
       "            ).addTo(map_8637fccdcb7edd1dd1dcbe4a9ec85b0b);\n",
       "        \n",
       "    \n",
       "        var popup_4e04676aa9a85fe1b67467d39a9a34e9 = L.popup({&quot;maxWidth&quot;: 500});\n",
       "\n",
       "        \n",
       "            \n",
       "                var i_frame_1f1c77fb75a67684df72b610c074826a = $(`&lt;iframe src=&quot;data:text/html;charset=utf-8;base64,CiAgICA8bGluayByZWw9InN0eWxlc2hlZXQiIHR5cGU9InRleHQvY3NzIiBocmVmPSJzdHlsZXMuY3NzIj48aDQgc3R5bGU9InRleHQtYWxpZ246Y2VudGVyOyI+U3VuZGVybGFuZCwgVW5pdGVkIEtpbmdkb208L2g0Pjxicj48cD48Yj5Db3Vyc2U6PC9iPiBBZHZhbmNlZCBDbGluaWNhbCBQcmFjdGl0aW9uZXIgLSBNU2M8L3A+PHA+PGI+VW5pdmVyc2l0eTo8L2I+IFVuaXZlcnNpdHkgb2YgU3VuZGVybGFuZDwvcD48cD48Yj5UdWl0aW9uIGluIFVTRDo8L2I+IFZpc2l0IHRoZSB3ZWJzaXRlPC9wPjxwPjxiPlVSTDo8L2I+IDxhIGhyZWY9Imh0dHBzOi8vd3d3LmZpbmRhbWFzdGVycy5jb20vbWFzdGVycy1kZWdyZWVzL2NvdXJzZS9hZHZhbmNlZC1jbGluaWNhbC1wcmFjdGl0aW9uZXItbXNjLz9pMzU0ZDc1NThjNTc1MDEiIHRhcmdldD0iX2JsYW5rIj5odHRwczovL3d3dy5maW5kYW1hc3RlcnMuY29tL21hc3RlcnMtZGVncmVlcy9jb3Vyc2UvYWR2YW5jZWQtY2xpbmljYWwtcHJhY3RpdGlvbmVyLW1zYy8/aTM1NGQ3NTU4YzU3NTAxPC9hPjwvcD48YnI+PGJyPg==&quot; width=&quot;500&quot; style=&quot;border:none !important;&quot; height=&quot;500&quot;&gt;&lt;/iframe&gt;`)[0];\n",
       "                popup_4e04676aa9a85fe1b67467d39a9a34e9.setContent(i_frame_1f1c77fb75a67684df72b610c074826a);\n",
       "            \n",
       "        \n",
       "\n",
       "        marker_5042be753726871ff1529851749dacdd.bindPopup(popup_4e04676aa9a85fe1b67467d39a9a34e9)\n",
       "        ;\n",
       "\n",
       "        \n",
       "    \n",
       "    \n",
       "            var marker_b5c0c54fe9048b779acc0188cfa74f99 = L.marker(\n",
       "                [53.4071991, -2.99168],\n",
       "                {}\n",
       "            ).addTo(map_8637fccdcb7edd1dd1dcbe4a9ec85b0b);\n",
       "        \n",
       "    \n",
       "        var popup_02080ae35b6b2873141abfd8c1a6ee62 = L.popup({&quot;maxWidth&quot;: 500});\n",
       "\n",
       "        \n",
       "            \n",
       "                var i_frame_d081c15bfd319c1d133b0122f652561f = $(`&lt;iframe src=&quot;data:text/html;charset=utf-8;base64,CiAgICA8bGluayByZWw9InN0eWxlc2hlZXQiIHR5cGU9InRleHQvY3NzIiBocmVmPSJzdHlsZXMuY3NzIj48aDQgc3R5bGU9InRleHQtYWxpZ246Y2VudGVyOyI+TGl2ZXJwb29sLCBVbml0ZWQgS2luZ2RvbTwvaDQ+PGJyPjxwPjxiPkNvdXJzZTo8L2I+IEFkdmFuY2VkIFByYWN0aWNlIGluIEhlYWx0aGNhcmUgTVNjPC9wPjxwPjxiPlVuaXZlcnNpdHk6PC9iPiBVbml2ZXJzaXR5IG9mIExpdmVycG9vbDwvcD48cD48Yj5UdWl0aW9uIGluIFVTRDo8L2I+ICQyNzc1LjkyPC9wPjxwPjxiPlVSTDo8L2I+IDxhIGhyZWY9Imh0dHBzOi8vd3d3LmZpbmRhbWFzdGVycy5jb20vbWFzdGVycy1kZWdyZWVzL2NvdXJzZS9hZHZhbmNlZC1wcmFjdGljZS1pbi1oZWFsdGhjYXJlLW1zYy8/aTMyNmQ5MDhjNjIyODIiIHRhcmdldD0iX2JsYW5rIj5odHRwczovL3d3dy5maW5kYW1hc3RlcnMuY29tL21hc3RlcnMtZGVncmVlcy9jb3Vyc2UvYWR2YW5jZWQtcHJhY3RpY2UtaW4taGVhbHRoY2FyZS1tc2MvP2kzMjZkOTA4YzYyMjgyPC9hPjwvcD48YnI+PGJyPjxwPjxiPkNvdXJzZTo8L2I+IE1hbmFnZW1lbnQgYW5kIERpZ2l0YWwgQnVzaW5lc3MgKHdpdGggQWR2YW5jZWQgUHJhY3RpY2UpIE1TYzwvcD48cD48Yj5Vbml2ZXJzaXR5OjwvYj4gTGl2ZXJwb29sIEpvaG4gTW9vcmVzIFVuaXZlcnNpdHk8L3A+PHA+PGI+VHVpdGlvbiBpbiBVU0Q6PC9iPiBWaXNpdCB0aGUgd2Vic2l0ZTwvcD48cD48Yj5VUkw6PC9iPiA8YSBocmVmPSJodHRwczovL3d3dy5maW5kYW1hc3RlcnMuY29tL21hc3RlcnMtZGVncmVlcy9jb3Vyc2UvbWFuYWdlbWVudC1hbmQtZGlnaXRhbC1idXNpbmVzcy13aXRoLWFkdmFuY2VkLXByYWN0aWNlLW1zYy8/aTE0N2Q3ODczYzU1Njc3IiB0YXJnZXQ9Il9ibGFuayI+aHR0cHM6Ly93d3cuZmluZGFtYXN0ZXJzLmNvbS9tYXN0ZXJzLWRlZ3JlZXMvY291cnNlL21hbmFnZW1lbnQtYW5kLWRpZ2l0YWwtYnVzaW5lc3Mtd2l0aC1hZHZhbmNlZC1wcmFjdGljZS1tc2MvP2kxNDdkNzg3M2M1NTY3NzwvYT48L3A+PGJyPjxicj4=&quot; width=&quot;500&quot; style=&quot;border:none !important;&quot; height=&quot;500&quot;&gt;&lt;/iframe&gt;`)[0];\n",
       "                popup_02080ae35b6b2873141abfd8c1a6ee62.setContent(i_frame_d081c15bfd319c1d133b0122f652561f);\n",
       "            \n",
       "        \n",
       "\n",
       "        marker_b5c0c54fe9048b779acc0188cfa74f99.bindPopup(popup_02080ae35b6b2873141abfd8c1a6ee62)\n",
       "        ;\n",
       "\n",
       "        \n",
       "    \n",
       "    \n",
       "            var marker_417f2d00aa6186206b1c4bc32bddf60e = L.marker(\n",
       "                [52.4796992, -1.9026911],\n",
       "                {}\n",
       "            ).addTo(map_8637fccdcb7edd1dd1dcbe4a9ec85b0b);\n",
       "        \n",
       "    \n",
       "        var popup_e1eb6bacbbe0d7c054aae4f1b9ac1396 = L.popup({&quot;maxWidth&quot;: 500});\n",
       "\n",
       "        \n",
       "            \n",
       "                var i_frame_9afb9e704cfa557ce90007beec21efd0 = $(`&lt;iframe src=&quot;data:text/html;charset=utf-8;base64,CiAgICA8bGluayByZWw9InN0eWxlc2hlZXQiIHR5cGU9InRleHQvY3NzIiBocmVmPSJzdHlsZXMuY3NzIj48aDQgc3R5bGU9InRleHQtYWxpZ246Y2VudGVyOyI+QmlybWluZ2hhbSwgVW5pdGVkIEtpbmdkb208L2g0Pjxicj48cD48Yj5Db3Vyc2U6PC9iPiBBZHZhbmNlZCBQcmFjdGljZSBpbiBIZWFsdGhjYXJlIC0gTVNjL1BHRGlwL1BHQ2VydDwvcD48cD48Yj5Vbml2ZXJzaXR5OjwvYj4gVW5pdmVyc2l0eSBvZiBCaXJtaW5naGFtPC9wPjxwPjxiPlR1aXRpb24gaW4gVVNEOjwvYj4gVmlzaXQgdGhlIHdlYnNpdGU8L3A+PHA+PGI+VVJMOjwvYj4gPGEgaHJlZj0iaHR0cHM6Ly93d3cuZmluZGFtYXN0ZXJzLmNvbS9tYXN0ZXJzLWRlZ3JlZXMvY291cnNlL2FkdmFuY2VkLXByYWN0aWNlLWluLWhlYWx0aGNhcmUtbXNjLXBnZGlwLXBnY2VydC8/aTI4MmQ0MzA5YzQ4NTcyIiB0YXJnZXQ9Il9ibGFuayI+aHR0cHM6Ly93d3cuZmluZGFtYXN0ZXJzLmNvbS9tYXN0ZXJzLWRlZ3JlZXMvY291cnNlL2FkdmFuY2VkLXByYWN0aWNlLWluLWhlYWx0aGNhcmUtbXNjLXBnZGlwLXBnY2VydC8/aTI4MmQ0MzA5YzQ4NTcyPC9hPjwvcD48YnI+PGJyPg==&quot; width=&quot;500&quot; style=&quot;border:none !important;&quot; height=&quot;500&quot;&gt;&lt;/iframe&gt;`)[0];\n",
       "                popup_e1eb6bacbbe0d7c054aae4f1b9ac1396.setContent(i_frame_9afb9e704cfa557ce90007beec21efd0);\n",
       "            \n",
       "        \n",
       "\n",
       "        marker_417f2d00aa6186206b1c4bc32bddf60e.bindPopup(popup_e1eb6bacbbe0d7c054aae4f1b9ac1396)\n",
       "        ;\n",
       "\n",
       "        \n",
       "    \n",
       "&lt;/script&gt;\n",
       "&lt;/html&gt;\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
      ],
      "text/plain": [
       "<folium.folium.Map at 0x1d21dc32990>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example usage\n",
    "create_map(df_city_country_coordinates, query_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Map guide\n",
    "\n",
    "- This tool provides students with an enhanced visualization of the geographical locations of the master's degree programs they are searching for.\n",
    "\n",
    "- The map displays location icons on cities that host the master's degree programs of interest to the student.\n",
    "\n",
    "- Upon clicking a location icon, a pop-up tab appears, presenting detailed information about the master's degree program. This includes the course name, university name, tuition fees in USD, and a clickable URL leading to the official website of the master's degree program."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Bonus: Complex search engine "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach explanation\n",
    "\n",
    "- In this question 3 more inverted indices will be made using the same procedures used in the first inverted index in question 2(Conjuctive querying only).\n",
    "\n",
    "- The three inverted indices are for the columns 'CourseName', 'universityName', and 'city'.\n",
    "\n",
    "- After applying the search for each column, the results are concatenated together in the same dataframe.\n",
    "\n",
    "- Moreover, the searching filters(budget, countries, online modality) are applied to the aggregated dataframe.\n",
    "\n",
    "- The duplicates are dropped and the search result is returned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vocabulary of course names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocabulary for the 'courseName_lemmatized' column\n",
    "\n",
    "# Create a vocabulary\n",
    "course_vocab = set()\n",
    "\n",
    "# Extract words from the 'courseName_lemmatized' column\n",
    "for name in df_updated['courseName_lemmatized']:\n",
    "     \n",
    "     # Handling NaN/float values\n",
    "     if isinstance(name, str):  \n",
    "        words = name.split()\n",
    "        course_vocab.update(words)\n",
    "\n",
    "# Convert the vocabulary to a dictionary with words as keys and their index as values\n",
    "course_vocab_dict = {idx: word for idx, word in enumerate(course_vocab)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inverted index for the course names vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>documents_IDs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>earth</td>\n",
       "      <td>[3330, 2180, 2183, 2188, 2194, 4179, 2196, 219...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tradit</td>\n",
       "      <td>[3132]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>graphic</td>\n",
       "      <td>[1346, 3677]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>grenobl</td>\n",
       "      <td>[1351]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mim</td>\n",
       "      <td>[4280, 5538, 4759]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      word                                      documents_IDs\n",
       "0    earth  [3330, 2180, 2183, 2188, 2194, 4179, 2196, 219...\n",
       "1   tradit                                             [3132]\n",
       "2  graphic                                       [1346, 3677]\n",
       "3  grenobl                                             [1351]\n",
       "4      mim                                 [4280, 5538, 4759]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dictionary to store word occurrences with row indices\n",
    "inverted_index_course = {word: [] for word in course_vocab}\n",
    "\n",
    "# Iterate over rows to find occurrences\n",
    "i = 0\n",
    "for idx, course in enumerate(df_updated['courseName_lemmatized']):\n",
    "\n",
    "    # Handling NaN/float values\n",
    "    if isinstance(course, str):  \n",
    "        words = course.split()\n",
    "        for word in words:\n",
    "            if word in course_vocab:\n",
    "                inverted_index_course[word].append(idx)\n",
    "    \n",
    "# Create a DataFrame from the dictionary\n",
    "inverted_index_course = pd.DataFrame(list(inverted_index_course.items()), columns=['word', 'documents_IDs'])\n",
    "inverted_index_course['documents_IDs'] = inverted_index_course['documents_IDs'].apply(lambda x: list(set(x)))\n",
    "inverted_index_course.to_csv('inverted_index_course.csv', index=False)\n",
    "inverted_index_course.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vocabulary of university names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocabulary for the 'universityName_lemmatized' column\n",
    "\n",
    "# Create a vocabulary\n",
    "uni_vocab = set()\n",
    "\n",
    "# Extract words from the 'universityName_lemmatized' column\n",
    "for name in df_updated['universityName_lemmatized']:\n",
    "     \n",
    "     # Handling NaN/float values\n",
    "     if isinstance(name, str):  \n",
    "        words = name.split()\n",
    "        uni_vocab.update(words)\n",
    "\n",
    "# Convert the vocabulary to a dictionary with words as keys and their index as values\n",
    "uni_vocab_dict = {idx: word for idx, word in enumerate(uni_vocab)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inverted index for the university names vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>documents_IDs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>meridional</td>\n",
       "      <td>[5449]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aristotl</td>\n",
       "      <td>[2808]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eiphi</td>\n",
       "      <td>[5033, 5036, 5006, 4975, 4986, 4989, 4958, 5018]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>napier</td>\n",
       "      <td>[5165, 4941]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>universidad</td>\n",
       "      <td>[3074, 3717, 1823]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word                                     documents_IDs\n",
       "0   meridional                                            [5449]\n",
       "1     aristotl                                            [2808]\n",
       "2        eiphi  [5033, 5036, 5006, 4975, 4986, 4989, 4958, 5018]\n",
       "3       napier                                      [5165, 4941]\n",
       "4  universidad                                [3074, 3717, 1823]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dictionary to store word occurrences with row indices\n",
    "inverted_index_uni = {word: [] for word in uni_vocab}\n",
    "\n",
    "# Iterate over rows to find occurrences\n",
    "i = 0\n",
    "for idx, uni in enumerate(df_updated['universityName_lemmatized']):\n",
    "\n",
    "    # Handling NaN/float values\n",
    "    if isinstance(uni, str):  \n",
    "        words = uni.split()\n",
    "        for word in words:\n",
    "            if word in uni_vocab:\n",
    "                inverted_index_uni[word].append(idx)\n",
    "    \n",
    "# Create a DataFrame from the dictionary\n",
    "inverted_index_uni = pd.DataFrame(list(inverted_index_uni.items()), columns=['word', 'documents_IDs'])\n",
    "inverted_index_uni['documents_IDs'] = inverted_index_uni['documents_IDs'].apply(lambda x: list(set(x)))\n",
    "inverted_index_uni.to_csv('inverted_index_uni.csv', index=False)\n",
    "inverted_index_uni.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vocabulary of university cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocabulary for the 'city_lemmatized' column\n",
    "\n",
    "# Create a vocabulary\n",
    "cities_vocab = set()\n",
    "\n",
    "# Extract words from the 'city_lemmatized' column\n",
    "for city in df_updated['city_lemmatized']:\n",
    "     \n",
    "     # Handling NaN/float values\n",
    "     if isinstance(city, str):  \n",
    "        words = city.split()\n",
    "        cities_vocab.update(words)\n",
    "\n",
    "# Convert the vocabulary to a dictionary with words as keys and their index as values\n",
    "cities_vocab_dict = {idx: word for idx, word in enumerate(cities_vocab)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inverted index for the university cities vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>documents_IDs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>newport</td>\n",
       "      <td>[5921, 1860, 4038, 5980, 3980, 5907, 5909, 597...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lyon</td>\n",
       "      <td>[2402, 2435]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lausann</td>\n",
       "      <td>[5507, 5509]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nant</td>\n",
       "      <td>[4258, 3108, 1810, 1266, 275, 5014, 4666, 4731...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>passau</td>\n",
       "      <td>[4608, 4617, 4593, 4596, 4603, 4606]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      word                                      documents_IDs\n",
       "0  newport  [5921, 1860, 4038, 5980, 3980, 5907, 5909, 597...\n",
       "1     lyon                                       [2402, 2435]\n",
       "2  lausann                                       [5507, 5509]\n",
       "3     nant  [4258, 3108, 1810, 1266, 275, 5014, 4666, 4731...\n",
       "4   passau               [4608, 4617, 4593, 4596, 4603, 4606]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dictionary to store word occurrences with row indices\n",
    "inverted_index_cities = {word: [] for word in cities_vocab}\n",
    "\n",
    "# Iterate over rows to find occurrences\n",
    "i = 0\n",
    "for idx, city in enumerate(df_updated['city_lemmatized']):\n",
    "\n",
    "    # Handling NaN/float values\n",
    "    if isinstance(city, str):  \n",
    "        words = city.split()\n",
    "        for word in words:\n",
    "            if word in cities_vocab:\n",
    "                inverted_index_cities[word].append(idx)\n",
    "    \n",
    "# Create a DataFrame from the dictionary\n",
    "inverted_index_cities = pd.DataFrame(list(inverted_index_cities.items()), columns=['word', 'documents_IDs'])\n",
    "inverted_index_cities['documents_IDs'] = inverted_index_cities['documents_IDs'].apply(lambda x: list(set(x)))\n",
    "inverted_index_cities.to_csv('inverted_index_cities.csv', index=False)\n",
    "inverted_index_cities.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function that retrieves the user's search criteria\n",
    "\n",
    "def get_search_criteria():\n",
    "\n",
    "    # Get the coures name from the user\n",
    "    course = input('For any criterion you dont want to specify please type \"None\", \\n Enter the course name: ')\n",
    "\n",
    "    # Get the university name from the user\n",
    "    uni = input('Enter the university name: ')\n",
    "\n",
    "    # Get the university city from the user\n",
    "    city = input('Enter the university city: ')\n",
    "\n",
    "    # Get the user's maximum budget\n",
    "    budget = input('Enter your maximum budget (in USD): ')\n",
    "\n",
    "    # Get the user's preferred duration\n",
    "    started = input('Do want to consider only the courses that has started? (Yes/No): ')\n",
    "\n",
    "    # Get the user's preferred modality\n",
    "    modality = input('Enter your preferred modality (Online/On campus): ')\n",
    "\n",
    "    # Get the user's preferred location\n",
    "    location = input('Enter your preferred countries separated by a comma: ')\n",
    "    \n",
    "    # Split the string into a list using the comma as the delimiter\n",
    "    location = ''.join(location)\n",
    "    location = location.split(', ')\n",
    "    \n",
    "\n",
    "    # Create a dictionary to store the search criteria\n",
    "    search_criteria = {\n",
    "        'course': course,\n",
    "        'uni': uni,\n",
    "        'city': city,\n",
    "        'budget': budget,\n",
    "        'started': started,\n",
    "        'modality': modality,\n",
    "        'location': location,\n",
    "    }\n",
    "\n",
    "    return search_criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### User Manual\n",
    "\n",
    " **Steps:**\n",
    " \n",
    "    1. Course Name:\n",
    "        - Prompt the user to enter the course name.\n",
    "\n",
    "    2. University Name:\n",
    "        - Prompt the user to enter the university name.\n",
    "\n",
    "    3. University City:\n",
    "        - Prompt the user to enter the university city.\n",
    "\n",
    "    4. Budget\n",
    "        - Prompt the user to enter their maximum budget in USD.\n",
    "\n",
    "    5. Course Start\n",
    "        - Ask the user if they want to consider only courses that have already started (Yes/No).\n",
    "\n",
    "    6. Modality\n",
    "        - Prompt the user to enter their preferred modality (Online/On campus).\n",
    "\n",
    "    7. Location\n",
    "        - Prompt the user to enter their preferred countries, separated by commas.\n",
    "\n",
    "    - Input Validation\n",
    "        - The user *MUST* type \"None\" for any criterion they don't want to specify.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A dictionary containing the user's search criteria\n",
    "filters_dict = get_search_criteria()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_complex_query(query, inverted_index, df, filters_dict):\n",
    "    \n",
    "    # Apply text preprocessing to the query\n",
    "    processed_query = preprocess_text(query)\n",
    "\n",
    "    query_words = processed_query.split()\n",
    "\n",
    "    # Find document_IDs for each word in the query using the inverted index\n",
    "    result_document_ids = []\n",
    "    \n",
    "    for word in query_words:\n",
    "\n",
    "        if word in inverted_index['word'].values:\n",
    "\n",
    "            # Get the document_IDs for the current word\n",
    "            word_document_ids = inverted_index.loc[inverted_index['word'] == word, 'documents_IDs'].values[0]\n",
    "\n",
    "            # Add the document_IDs to the result list\n",
    "            result_document_ids.extend(word_document_ids)\n",
    "\n",
    "    # Remove duplicate document_IDs\n",
    "    result_document_ids = list(set(result_document_ids))\n",
    "    result_document_ids.sort()\n",
    "    \n",
    "    # Return the rows corresponding to the document_IDs\n",
    "    result =  df.loc[result_document_ids, ['courseName', 'universityName', 'description', 'city', 'startDate' ,'country', 'administration', \n",
    "                                           'fees_USD',  'url']]\n",
    "\n",
    "    # Applying the search criteria\n",
    "\n",
    "    if filters_dict['course'] != 'None':\n",
    "        course = preprocess_text(filters_dict['course'])\n",
    "        course_words = course.split()\n",
    "\n",
    "        # Find document_IDs for each word in the query using the inverted index\n",
    "        result_document_ids = []\n",
    "\n",
    "        for word in course_words:\n",
    "\n",
    "            if word in inverted_index_course['word'].values:\n",
    "\n",
    "                # Get the document_IDs for the current word\n",
    "                word_document_ids = inverted_index_course.loc[inverted_index_course['word'] == word, 'documents_IDs'].values[0]\n",
    "\n",
    "                # Add the document_IDs to the result list\n",
    "                result_document_ids.extend(word_document_ids)\n",
    "\n",
    "    # Remove duplicate document_IDs\n",
    "    result_document_ids = list(set(result_document_ids))\n",
    "    result_document_ids.sort()\n",
    "\n",
    "    result1 =  df.loc[result_document_ids, ['courseName', 'universityName', 'description', 'city', 'startDate' ,'country', 'administration',\n",
    "                                            'fees_USD', 'url']]\n",
    "\n",
    "    if filters_dict['uni'] != 'None':\n",
    "        uni = preprocess_text(filters_dict['uni'])\n",
    "        uni_words = uni.split()\n",
    "\n",
    "        # Find document_IDs for each word in the query using the inverted index\n",
    "        result_document_ids = []\n",
    "\n",
    "        for word in uni_words:\n",
    "\n",
    "            if word in inverted_index_uni['word'].values:\n",
    "\n",
    "                # Get the document_IDs for the current word\n",
    "                word_document_ids = inverted_index_uni.loc[inverted_index_uni['word'] == word, 'documents_IDs'].values[0]\n",
    "\n",
    "                # Add the document_IDs to the result list\n",
    "                result_document_ids.extend(word_document_ids)\n",
    "\n",
    "    # Remove duplicate document_IDs\n",
    "    result_document_ids = list(set(result_document_ids))\n",
    "    result_document_ids.sort()\n",
    "\n",
    "    result2 =  df.loc[result_document_ids, ['courseName', 'universityName', 'description', 'city', 'startDate' ,'country', 'administration',\n",
    "                                            'fees_USD',  'url']]\n",
    "    \n",
    "\n",
    "\n",
    "    if filters_dict['city'] != 'None':\n",
    "        city = preprocess_text(filters_dict['city'])\n",
    "        city_words = city.split()\n",
    "\n",
    "        # Find document_IDs for each word in the query using the inverted index\n",
    "        result_document_ids = []\n",
    "\n",
    "        for word in city_words:\n",
    "\n",
    "            if word in inverted_index_cities['word'].values:\n",
    "\n",
    "                # Get the document_IDs for the current word\n",
    "                word_document_ids = inverted_index_cities.loc[inverted_index_cities['word'] == word, 'documents_IDs'].values[0]\n",
    "\n",
    "                # Add the document_IDs to the result list\n",
    "                result_document_ids.extend(word_document_ids)\n",
    "\n",
    "    # Remove duplicate document_IDs\n",
    "    result_document_ids = list(set(result_document_ids))\n",
    "    result_document_ids.sort()\n",
    "\n",
    "    result3 =  df.loc[result_document_ids, ['courseName', 'universityName', 'description', 'city', 'startDate' ,'country', 'administration',\n",
    "                                            'fees_USD',  'url']]\n",
    "\n",
    "    # Aggregating the data from the different inverted indices\n",
    "    result = pd.concat([result, result1, result2, result3], ignore_index=True)\n",
    "    \n",
    "    if result is not None:\n",
    "        \n",
    "    # Applying budget filter\n",
    "        if filters_dict['budget'] != 'None':\n",
    "            result = result.drop(result[result['fees_USD'] < float(filters_dict['budget'])].index, inplace=False)\n",
    "\n",
    "        # applying modality filter\n",
    "        if filters_dict['modality'] != 'None':\n",
    "            result = result.drop(result[result['administration'] != filters_dict['modality']].index, inplace=False)\n",
    "\n",
    "        # Applying university filter\n",
    "        if filters_dict['uni'] != 'None':\n",
    "                result = result.drop(result[result['universityName'] != filters_dict['uni']].index, inplace=False)\n",
    "\n",
    "        # Applying countries filter \n",
    "        if filters_dict['location'] != 'None':\n",
    "                result = result.drop(result[~result['country'].isin(filters_dict['location'])].index, inplace=False)\n",
    "\n",
    "        # Applying city filter\n",
    "        if filters_dict['city'] != 'None':\n",
    "            result = result.drop(result[result['city'] != filters_dict['city']].index, inplace=False)\n",
    "\n",
    "    #Drop duplicates    \n",
    "    result = result.drop_duplicates()\n",
    "\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>courseName</th>\n",
       "      <th>universityName</th>\n",
       "      <th>description</th>\n",
       "      <th>city</th>\n",
       "      <th>startDate</th>\n",
       "      <th>country</th>\n",
       "      <th>administration</th>\n",
       "      <th>fees_USD</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>Clinical Neurology (by Distance Learning) MSc</td>\n",
       "      <td>University College London</td>\n",
       "      <td>Register your interest in graduate study at UC...</td>\n",
       "      <td>London</td>\n",
       "      <td>September</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Online</td>\n",
       "      <td>11186.52</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3378</th>\n",
       "      <td>Business Information Systems Management MSc</td>\n",
       "      <td>Middlesex University</td>\n",
       "      <td>Business information, and using it to increase...</td>\n",
       "      <td>London</td>\n",
       "      <td>October, January</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Online</td>\n",
       "      <td>12455.91</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3421</th>\n",
       "      <td>International Public Policy MSc</td>\n",
       "      <td>Queen Mary University of London</td>\n",
       "      <td>Start date: January 2024The International Publ...</td>\n",
       "      <td>London</td>\n",
       "      <td>May, September</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Online</td>\n",
       "      <td>10547.85</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3600</th>\n",
       "      <td>Developmental Transactional Analysis [DTA]</td>\n",
       "      <td>Professional Development International</td>\n",
       "      <td>Transactional analysis is often associated wit...</td>\n",
       "      <td>London</td>\n",
       "      <td>Any Month</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Online</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         courseName  \\\n",
       "459   Clinical Neurology (by Distance Learning) MSc   \n",
       "3378    Business Information Systems Management MSc   \n",
       "3421                International Public Policy MSc   \n",
       "3600     Developmental Transactional Analysis [DTA]   \n",
       "\n",
       "                              universityName  \\\n",
       "459                University College London   \n",
       "3378                    Middlesex University   \n",
       "3421         Queen Mary University of London   \n",
       "3600  Professional Development International   \n",
       "\n",
       "                                            description    city  \\\n",
       "459   Register your interest in graduate study at UC...  London   \n",
       "3378  Business information, and using it to increase...  London   \n",
       "3421  Start date: January 2024The International Publ...  London   \n",
       "3600  Transactional analysis is often associated wit...  London   \n",
       "\n",
       "             startDate         country administration  fees_USD  \\\n",
       "459          September  United Kingdom         Online  11186.52   \n",
       "3378  October, January  United Kingdom         Online  12455.91   \n",
       "3421    May, September  United Kingdom         Online  10547.85   \n",
       "3600         Any Month  United Kingdom         Online       NaN   \n",
       "\n",
       "                                                    url  \n",
       "459   https://www.findamasters.com/masters-degrees/c...  \n",
       "3378  https://www.findamasters.com/masters-degrees/c...  \n",
       "3421  https://www.findamasters.com/masters-degrees/c...  \n",
       "3600  https://www.findamasters.com/masters-degrees/c...  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example usage\n",
    "filters_dict = { 'course': 'advanced knowledge', 'uni': 'None', 'city': 'London', 'budget': '10000', 'started': 'Yes', 'modality': 'Online',\n",
    "                 'location': ['United Kingdom', 'England', 'Germany', 'France', 'Spain', 'Italy', 'Netherlands', 'Sweden', 'Switzerland', 'Belgium', 'Austria', 'Denmark',\n",
    "                               'Norway', 'Finland', 'Ireland', 'Portugal', 'Greece', 'Poland', 'Romania', 'Czech Republic', 'Hungary', 'Bulgaria', 'Croatia', 'Slovakia']}\n",
    "\n",
    "complex_search = execute_complex_query('advanced knowledge', inverted_index, df_updated, filters_dict)\n",
    "complex_search.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Command Line Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As done in the previous assignment, we encourage using the command as a feature that Data Scientists must master.\n",
    "\n",
    "Note: To answer the question in this section, you must strictly use command line tools. We will reject any other method of response. The final script must be placed in CommandLine.sh.\n",
    "\n",
    "First, take the course_i.tsv files you created in point 1 and merge them using Linux commands (Hint: make sure that the first row containing the column names appears only once).\n",
    "\n",
    "Now that you have your merged file named merged_courses.tsv, use Linux commands to answer the following questions:\n",
    "\n",
    "Which country offers the most Master's Degrees? Which city?\n",
    "How many colleges offer Part-Time education?\n",
    "Print the percentage of courses in Engineering (the word \"Engineer\" is contained in the course's name).\n",
    "Important note: You may work on this question in any environment (AWS, your PC command line, Jupyter notebook, etc.), but the final script must be placed in CommandLine.sh, which must be executable. Please run the script and include a screenshot of the output in the notebook for evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Script Purpose\n",
    "\n",
    "The script is designed to merge data from multiple TSV (Tab-Separated Values) files into a single file and then perform specific analyses on the merged data. The analyses include finding which country and city offer the most Master's Degrees, counting how many colleges offer Part-Time education, and calculating the percentage of courses related to Engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Script Breakdown\n",
    "\n",
    "Setting Up the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This line indicates that the script should be run using the Bash shell, a common command-line interpreter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DIR=\"/Users/onurozansunger/Desktop/ADM-HW3-Group-26/HW3/courses_tsv\"\n",
    "cd $DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These lines set the working directory to the folder containing the TSV files and then change to that directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing the Merged File:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "> merged_courses.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This command creates (or clears, if it already exists) a file named merged_courses.tsv. This file will be used to store the merged data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging Data from Individual Files"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for i in {0..5999}\n",
    "do\n",
    "    FILE=\"course_$i.tsv\"\n",
    "    if [ -f \"$FILE\" ]; then\n",
    "        head -n 1 \"$FILE\" >> merged_courses.tsv\n",
    "    fi\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This loop iterates over file names from course_0.tsv to course_5999.tsv.\n",
    "\n",
    "For each file, it checks if the file exists (-f \"$FILE\").\n",
    "\n",
    "If the file exists, it takes the first line from each file (head -n 1 \"$FILE\") and appends it to merged_courses.tsv. This is done because the data of interest is in the header line of each file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Analysis\n",
    "\n",
    "The script performs several analyses on the merged data:\n",
    "\n",
    "1. Find the Country with the Most Master's Degrees:\n",
    "\n",
    "Method: Utilizes awk to filter rows where the degree type column matches \"MSc\".\n",
    "\n",
    "Process: Sorts and counts occurrences by country.\n",
    "\n",
    "Output: Displays the country with the highest count.\n",
    "\n",
    "2. Find the City with the Most Master's Degrees:\n",
    "\n",
    "Method: Similar to the country analysis, but focuses on cities.\n",
    "\n",
    "Process: Sorts and counts occurrences by city.\n",
    "\n",
    "Output: Shows the city with the most Master's Degrees.\n",
    "\n",
    "3. Count Colleges Offering Part-Time Education:\n",
    "\n",
    "Method: Filters rows where the education mode column matches \"Part Time\".\n",
    "\n",
    "Process: Counts unique college names that offer part-time education.\n",
    "\n",
    "Output: Provides the total number of colleges offering part-time education.\n",
    "\n",
    "4. Calculate the Percentage of Engineering Courses:\n",
    "\n",
    "Method: Counts the total number of courses and the number of courses with \"Engineering\" or \"Engineer\" in their names.\n",
    "\n",
    "Process: Calculates the percentage of engineering courses in relation to the total course count.\n",
    "\n",
    "Output: Shows the percentage of engineering courses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output Results\n",
    "\n",
    "The script concludes by echoing the results of the analyses to the console, providing insights into the dataset's contents in terms of degree types, education modes, and course subjects."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "echo \"Country with the most Master's Degrees: $most_masters_country\"\n",
    "echo \"City with the most Master's Degrees: $most_masters_city\"\n",
    "echo \"Number of colleges offering Part-Time education: $part_time_colleges\"\n",
    "echo \"Percentage of Engineering courses: $engineering_percentage%\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full script:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#!/bin/bash\n",
    "\n",
    "# Define the directory containing the TSV files\n",
    "DIR=\"/Users/onurozansunger/Desktop/ADM-HW3-Group-26/HW3/courses_tsv\"\n",
    "\n",
    "# Navigate to the directory\n",
    "cd $DIR\n",
    "\n",
    "# Initialize the merged file (it will be empty initially)\n",
    "> merged_courses.tsv\n",
    "\n",
    "# Append the first line (header) of each file\n",
    "for i in {0..5999}\n",
    "do\n",
    "    FILE=\"course_$i.tsv\"\n",
    "    if [ -f \"$FILE\" ]; then\n",
    "        head -n 1 \"$FILE\" >> merged_courses.tsv\n",
    "    fi\n",
    "done\n",
    "\n",
    "# Adjusted Column numbers based on the provided file structure\n",
    "degree_type_col=8\n",
    "education_mode_col=4\n",
    "city_col=10\n",
    "country_col=11\n",
    "course_name_col=1\n",
    "\n",
    "# Find the country with the most Master's Degrees\n",
    "most_masters_country=$(awk -F'\\t' -v col=\"$degree_type_col\" -v country=\"$country_col\" \\\n",
    "    '$col==\"MSc\" {print $country}' merged_courses.tsv | sort | uniq -c | sort -nr | head -n 1)\n",
    "\n",
    "# Find the city with the most Master's Degrees\n",
    "most_masters_city=$(awk -F'\\t' -v col=\"$degree_type_col\" -v city=\"$city_col\" \\\n",
    "    '$col==\"MSc\" {print $city}' merged_courses.tsv | sort | uniq -c | sort -nr | head -n 1)\n",
    "\n",
    "# Count how many colleges offer Part-Time education\n",
    "part_time_colleges=$(awk -F'\\t' -v mode=\"$education_mode_col\" \\\n",
    "    '$mode ~ /Part Time/' merged_courses.tsv | cut -f 2 | sort | uniq | wc -l)\n",
    "\n",
    "# Calculate the percentage of Engineering courses\n",
    "total_courses=$(wc -l < merged_courses.tsv)\n",
    "engineering_courses=$(awk -F'\\t' -v name=\"$course_name_col\" \\\n",
    "    '$name ~ /Engineering|Engineer/' merged_courses.tsv | wc -l)\n",
    "engineering_percentage=$((engineering_courses * 100 / total_courses))\n",
    "\n",
    "# Output the results\n",
    "echo \"Country with the most Master's Degrees: $most_masters_country\"\n",
    "echo \"City with the most Master's Degrees: $most_masters_city\"\n",
    "echo \"Number of colleges offering Part-Time education: $part_time_colleges\"\n",
    "echo \"Percentage of Engineering courses: $engineering_percentage%\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Screenshot:\n",
    "\n",
    "![foto.png](foto.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithmic Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Implement a code to solve the above mentioned problem.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol_found = False\n",
    "\n",
    "def reports_generation(list_hours, sumHours, partial_solution=[], idx=0, report=[]):\n",
    "    global sol_found\n",
    "\n",
    "    #Stop if a solution is found\n",
    "    if sol_found:\n",
    "        return\n",
    "\n",
    "    if idx == len(list_hours):\n",
    "        if sum(partial_solution) == sumHours:\n",
    "            report.append(partial_solution.copy())\n",
    "            sol_found = True\n",
    "        return\n",
    "\n",
    "    for element in list_hours[idx]:\n",
    "        partial_solution.append(element)\n",
    "        #Prune the partial solutions with an amount of hours > sumHours\n",
    "        if sum(partial_solution) <= sumHours:\n",
    "            reports_generation(list_hours, sumHours, partial_solution, idx + 1, report)\n",
    "        partial_solution.pop()\n",
    "\n",
    "    reports_generation(list_hours, sumHours, partial_solution, idx + 1, report)\n",
    "\n",
    "    return report\n",
    "\n",
    "def main():\n",
    "    global sol_found\n",
    "\n",
    "    line1 = input().split()\n",
    "    d = int(line1[0])\n",
    "    sumHours = int(line1[1])\n",
    "\n",
    "    min_max_hours = []\n",
    "    list_hours = []\n",
    "\n",
    "    for i in range(d):\n",
    "        line = input().split()\n",
    "        min_max_hours.append((int(line[0]), int(line[1])))\n",
    "        list_hours.append(list(range(min_max_hours[-1][0], min_max_hours[-1][1] + 1)))\n",
    "\n",
    "    sol_found = False\n",
    "    reports = reports_generation(list_hours, sumHours)\n",
    "\n",
    "    if len(reports) == 0:\n",
    "        print(\"NO\")\n",
    "    else:\n",
    "        print(\"YES\")\n",
    "        print(\" \".join(map(str, reports[0])))\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **What is the time complexity (the Big O notation) of your solution? Please provide a detailed explanation of how you calculated the time complexity.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the complexity of the algorithm is exponential. Let's define L_i as the number of candidate hours to work for each day, for example, if we have a day with min_hour = 3 and max_hour = 5, the list will be [3, 4, 5] and therefore L will be equal to 3.\n",
    "\n",
    "As we have D days, and we must generate all possible combinations between the D days, the cost consists of seeing if each element of the different lists would be part of the final solution or not, this is defined by the formula $2^{L_1 + L_2 + \\ldots + L_N}$, so the cost is exponential.\n",
    "\n",
    "Then the cost of generating the lists with the different available hours of each day is O(n), that is, linear with respect to the number of days.\n",
    "\n",
    "Therefore, the complexity is O($2^{L_1 + L_2 + \\ldots + L_N}$).\n",
    "\n",
    "It must be remembered that this would be in the worst case, that is, finding a solution at the end such that the sum of the elements of the list found is equal to sumHours.\n",
    "\n",
    "In our case, we make the code more efficient since when we find a first solution, we end the algorithm and also, those partial solutions that make the number of hours exceed sumHours are discarded and do not continue generating combinations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Ask ChatGPT or any other LLM chatbot tool to check your code's time complexity (the Big O notation). Compare your answer to theirs. Do you believe this is correct? If the two differ, which one is right? (why?)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The answer of Bing AI is:\n",
    "\n",
    "The time complexity of the given code is O($n^m$), where n is the maximum number of hours in a day and m is the number of days. This is because the code generates all possible combinations of hours for each day, which results in a time complexity that is exponential in the number of days. The reports_generation function is a recursive function that generates all possible combinations of hours for each day, and it is called for each day and for each possible number of hours in a day. Therefore, the time complexity is proportional to the number of possible combinations, which is n^m. However, please note that the actual time complexity may be less than this because the function returns as soon as a solution is found, and it also prunes partial solutions with a total number of hours greater than the required sum of hours. This pruning can significantly reduce the number of combinations that need to be generated and checked, especially if a solution is found early or if the required sum of hours is small compared to the total number of hours available. But in the worst-case scenario, the time complexity is still O($n^m$).\n",
    "\n",
    "I think my solution is more concrete, the Bing AI solution, is more general, since it assumes that all lists have as many hours as the maximum hours of all days, however, my solution takes into account only the number of hours each day. That is, my solution represents the possible combinations of hours for all days while the AI solution represents the possible combinations of hours for each day.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **What do you think of the optimality of your code? Do you believe it is optimal? Can you improve? Please elaborate on your response.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have decided to use recursion to solve the problem. The code already includes some improvements, such as stopping generating solutions that already exceed sumHours or stopping when a solution has been found by using a boolean as a global variable. To make it more optimal, dynamic programming could have been used, using top down or bottom up, some function calls could have been saved in some container so as not to repeat calculations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
